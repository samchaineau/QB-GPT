{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gohwn7N_b3TF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "env = \"gdrive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if env != \"local\":\n",
        "  !git clone https://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@github.com/samchaineau/QB-GPT.git\n",
        "  import sys\n",
        "  sys.path.append(\"/content/QB-GPT/\")"
      ],
      "metadata": {
        "id": "iu7_UHcLMm0j",
        "outputId": "d7c274a7-d337-4bd0-8aaf-548802ebae21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'QB-GPT'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 98 (delta 41), reused 77 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (98/98), 119.35 KiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Snyy4yk1MSuv",
        "outputId": "dd92373c-2ef7-437f-9e2c-b35b71ecb9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "if env == \"local\":\n",
        "    os.chdir(\"/Users/samuel/Documents/GitHub/QB-GPT/\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    os.chdir(\"/content/gdrive/MyDrive/NFL_Challenge/QB-GPT/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dZk4pGEcWJn",
        "outputId": "61b6a4d3-c33e-44ce-e5cd-431481ab920b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_preprocessing', 'data_models', 'index', 'models']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZC8PlPFzcaLL"
      },
      "outputs": [],
      "source": [
        "training_data = tf.data.Dataset.load(\"data_models/QBGPT/train_tokens_NFL_GPT\")\n",
        "testing_data = tf.data.Dataset.load(\"data_models/QBGPT/test_tokens_NFL_GPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qHqmx-rHkAqZ"
      },
      "outputs": [],
      "source": [
        "train_length = [i for i,_ in enumerate(training_data)][-1] + 1\n",
        "test_length = [i for i,_ in enumerate(testing_data)][-1] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G74adOrokP8G",
        "outputId": "efb4b24f-e680-4bf8-9fd7-f8022b2b1ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train length is :  205851\n",
            "Test length is :  51463\n"
          ]
        }
      ],
      "source": [
        "print(\"Train length is : \", str(train_length))\n",
        "print(\"Test length is : \", str(test_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TisoHo24c-2_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "training_data = training_data.shuffle(train_length).batch(batch_size)\n",
        "testing_data = testing_data.shuffle(test_length).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxvvriqbc2f-"
      },
      "source": [
        "## Model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JLxwB6r9263v"
      },
      "outputs": [],
      "source": [
        "def insert_weights(df, w):\n",
        "  df[\"weights\"] = [w for i in range(df.shape[0])]\n",
        "  return df\n",
        "\n",
        "class_weights = pd.read_parquet(\"models/modeling/QBGPT/class_weights.parquet\")\n",
        "\n",
        "step_range = [(0, 10), (10, 100), (100, 1000), (1000, 10000), (10000, 50000), (50000, 100000), (100000, 300000), (300000, 500000), (500000, 1000000), (1000000, 10000000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qYgHoVIw-tHN"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "weights = dict(Counter(class_weights[\"Zone_ID\"].to_numpy()))\n",
        "weights_df = pd.DataFrame(np.array([[k, v] for k,v in weights.items()]), columns = [\"Class\", \"Count\"])\n",
        "\n",
        "weights_dict = {i : weights_df[(weights_df['Count'] > step_range[i][0]) & (weights_df['Count'] <= step_range[i][1])].reset_index(drop = True) for i in range(len(step_range))}\n",
        "w_dict = {0 : 1,\n",
        "          1 : 0.9,\n",
        "          2 : 0.8,\n",
        "          3 : 0.7,\n",
        "          4 : 0.6,\n",
        "          5 : 0.5,\n",
        "          6 : 0.4,\n",
        "          7 : 0.3,\n",
        "          8 : 0.2,\n",
        "          9 : 0.05,}\n",
        "\n",
        "weights_dict = {k:insert_weights(v, w_dict[k]) for k,v in weights_dict.items()}\n",
        "\n",
        "weights_df = pd.concat(list(weights_dict.values())).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L4i4OY-o2PbX"
      },
      "outputs": [],
      "source": [
        "weights_inv = {v[0] : v[2] for v in weights_df.values}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights_inv.keys())"
      ],
      "metadata": {
        "id": "kXiP2NSCUGJv",
        "outputId": "da748be2-bff4-4728-a39b-fe1078e8b5f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10876"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yrfmrVSWwKeI"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return 3e-3\n",
        "  elif (epoch >= 1) & (epoch < 2):\n",
        "    return 2e-3\n",
        "  elif (epoch >= 2) & (epoch < 3):\n",
        "    return 1e-3\n",
        "  elif (epoch >= 3) & (epoch < 5):\n",
        "    return 5e-4\n",
        "  elif (epoch >= 5) & (epoch < 7):\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 5e-5\n",
        "\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vZnjt9Sli6S9"
      },
      "outputs": [],
      "source": [
        "from models.modeling.QBGPT.models import QBGPT, LargeQBGPT, XLargeQBGPT\n",
        "from models.modeling.QBGPT.losses_and_metrics import CustomSparseCategoricalAccuracy, CustomTopKAccuracy, CustomSparseCategoricalCrossentropy\n",
        "\n",
        "moves_to_pred = 10876\n",
        "input_size = 10878\n",
        "starts_size = 1033\n",
        "scrimmage_size = 100\n",
        "positions_id = 29\n",
        "temp_ids = 52\n",
        "\n",
        "off_def_size = 2\n",
        "token_type_size = 2\n",
        "play_type_size = 9\n",
        "\n",
        "model_large = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 512,\n",
        "                    hidden_dim = 512,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_medium = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 256,\n",
        "                    hidden_dim = 256,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_small = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 128,\n",
        "                    hidden_dim = 128,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_tiny = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 64,\n",
        "                    hidden_dim = 64,\n",
        "                    to_pred_size = moves_to_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_tiny.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_tiny = model_tiny.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_tiny.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_tiny.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_tiny.save_weights(\"models/modeling/QBGPT/weights/model_tiny/QBGPT\")"
      ],
      "metadata": {
        "id": "2y_DOiMxN80M",
        "outputId": "b5a4f2bd-f916-4d64-cc60-8c90985c36ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 482s 71ms/step - loss: 1.3013 - custom_sparse_categorical_accuracy: 0.5040 - custom_top_3_accuracy: 0.7846 - custom_top_5_accuracy: 0.8956 - val_loss: 1.1529 - val_custom_sparse_categorical_accuracy: 0.5287 - val_custom_top_3_accuracy: 0.8162 - val_custom_top_5_accuracy: 0.9239 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 296s 44ms/step - loss: 1.1543 - custom_sparse_categorical_accuracy: 0.5292 - custom_top_3_accuracy: 0.8165 - custom_top_5_accuracy: 0.9240 - val_loss: 1.1198 - val_custom_sparse_categorical_accuracy: 0.5380 - val_custom_top_3_accuracy: 0.8263 - val_custom_top_5_accuracy: 0.9312 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 287s 43ms/step - loss: 1.1268 - custom_sparse_categorical_accuracy: 0.5376 - custom_top_3_accuracy: 0.8244 - custom_top_5_accuracy: 0.9293 - val_loss: 1.0977 - val_custom_sparse_categorical_accuracy: 0.5462 - val_custom_top_3_accuracy: 0.8329 - val_custom_top_5_accuracy: 0.9349 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 283s 42ms/step - loss: 1.1136 - custom_sparse_categorical_accuracy: 0.5418 - custom_top_3_accuracy: 0.8281 - custom_top_5_accuracy: 0.9317 - val_loss: 1.0883 - val_custom_sparse_categorical_accuracy: 0.5497 - val_custom_top_3_accuracy: 0.8359 - val_custom_top_5_accuracy: 0.9367 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 282s 42ms/step - loss: 1.1112 - custom_sparse_categorical_accuracy: 0.5424 - custom_top_3_accuracy: 0.8288 - custom_top_5_accuracy: 0.9322 - val_loss: 1.0865 - val_custom_sparse_categorical_accuracy: 0.5503 - val_custom_top_3_accuracy: 0.8364 - val_custom_top_5_accuracy: 0.9371 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 282s 42ms/step - loss: 1.1029 - custom_sparse_categorical_accuracy: 0.5457 - custom_top_3_accuracy: 0.8314 - custom_top_5_accuracy: 0.9337 - val_loss: 1.0807 - val_custom_sparse_categorical_accuracy: 0.5526 - val_custom_top_3_accuracy: 0.8384 - val_custom_top_5_accuracy: 0.9382 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 282s 42ms/step - loss: 1.1019 - custom_sparse_categorical_accuracy: 0.5459 - custom_top_3_accuracy: 0.8317 - custom_top_5_accuracy: 0.9340 - val_loss: 1.0802 - val_custom_sparse_categorical_accuracy: 0.5530 - val_custom_top_3_accuracy: 0.8385 - val_custom_top_5_accuracy: 0.9382 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 282s 42ms/step - loss: 1.1005 - custom_sparse_categorical_accuracy: 0.5464 - custom_top_3_accuracy: 0.8321 - custom_top_5_accuracy: 0.9342 - val_loss: 1.0795 - val_custom_sparse_categorical_accuracy: 0.5532 - val_custom_top_3_accuracy: 0.8388 - val_custom_top_5_accuracy: 0.9384 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 280s 42ms/step - loss: 1.1002 - custom_sparse_categorical_accuracy: 0.5464 - custom_top_3_accuracy: 0.8322 - custom_top_5_accuracy: 0.9342 - val_loss: 1.0792 - val_custom_sparse_categorical_accuracy: 0.5533 - val_custom_top_3_accuracy: 0.8388 - val_custom_top_5_accuracy: 0.9384 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZEJDthj2iOT",
        "outputId": "a3b7c683-07b3-42fa-df76-d4548705ea5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 480s 72ms/step - loss: 1.2516 - custom_sparse_categorical_accuracy: 0.5143 - custom_top_3_accuracy: 0.7972 - custom_top_5_accuracy: 0.9065 - val_loss: 1.1336 - val_custom_sparse_categorical_accuracy: 0.5343 - val_custom_top_3_accuracy: 0.8225 - val_custom_top_5_accuracy: 0.9291 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 303s 45ms/step - loss: 1.1228 - custom_sparse_categorical_accuracy: 0.5382 - custom_top_3_accuracy: 0.8257 - custom_top_5_accuracy: 0.9308 - val_loss: 1.1022 - val_custom_sparse_categorical_accuracy: 0.5433 - val_custom_top_3_accuracy: 0.8315 - val_custom_top_5_accuracy: 0.9348 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 292s 44ms/step - loss: 1.0959 - custom_sparse_categorical_accuracy: 0.5466 - custom_top_3_accuracy: 0.8332 - custom_top_5_accuracy: 0.9356 - val_loss: 1.0834 - val_custom_sparse_categorical_accuracy: 0.5499 - val_custom_top_3_accuracy: 0.8367 - val_custom_top_5_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 290s 43ms/step - loss: 1.0830 - custom_sparse_categorical_accuracy: 0.5508 - custom_top_3_accuracy: 0.8369 - custom_top_5_accuracy: 0.9380 - val_loss: 1.0728 - val_custom_sparse_categorical_accuracy: 0.5541 - val_custom_top_3_accuracy: 0.8401 - val_custom_top_5_accuracy: 0.9399 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 285s 43ms/step - loss: 1.0805 - custom_sparse_categorical_accuracy: 0.5514 - custom_top_3_accuracy: 0.8375 - custom_top_5_accuracy: 0.9384 - val_loss: 1.0711 - val_custom_sparse_categorical_accuracy: 0.5542 - val_custom_top_3_accuracy: 0.8403 - val_custom_top_5_accuracy: 0.9401 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 290s 43ms/step - loss: 1.0726 - custom_sparse_categorical_accuracy: 0.5544 - custom_top_3_accuracy: 0.8400 - custom_top_5_accuracy: 0.9399 - val_loss: 1.0658 - val_custom_sparse_categorical_accuracy: 0.5569 - val_custom_top_3_accuracy: 0.8421 - val_custom_top_5_accuracy: 0.9410 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 290s 43ms/step - loss: 1.0712 - custom_sparse_categorical_accuracy: 0.5549 - custom_top_3_accuracy: 0.8404 - custom_top_5_accuracy: 0.9401 - val_loss: 1.0651 - val_custom_sparse_categorical_accuracy: 0.5572 - val_custom_top_3_accuracy: 0.8422 - val_custom_top_5_accuracy: 0.9412 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 287s 43ms/step - loss: 1.0699 - custom_sparse_categorical_accuracy: 0.5553 - custom_top_3_accuracy: 0.8408 - custom_top_5_accuracy: 0.9404 - val_loss: 1.0643 - val_custom_sparse_categorical_accuracy: 0.5575 - val_custom_top_3_accuracy: 0.8425 - val_custom_top_5_accuracy: 0.9413 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 287s 42ms/step - loss: 1.0696 - custom_sparse_categorical_accuracy: 0.5554 - custom_top_3_accuracy: 0.8409 - custom_top_5_accuracy: 0.9404 - val_loss: 1.0639 - val_custom_sparse_categorical_accuracy: 0.5576 - val_custom_top_3_accuracy: 0.8425 - val_custom_top_5_accuracy: 0.9414 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_small.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_small = model_small.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_small.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_small.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_small.save_weights(\"models/modeling/QBGPT/weights/model_small/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSx5kt044i17",
        "outputId": "dfffaa28-7dba-4480-e2c3-d6264c0cf924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  1780864   \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  1403004   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3183868 (12.15 MB)\n",
            "Trainable params: 3183612 (12.14 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_small.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YARcSnUXUz1",
        "outputId": "e9e307fc-bb55-4614-b06f-2c6a97f05f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 523s 78ms/step - loss: 1.2354 - custom_sparse_categorical_accuracy: 0.5174 - custom_top_3_accuracy: 0.8015 - custom_top_5_accuracy: 0.9107 - val_loss: 1.1258 - val_custom_sparse_categorical_accuracy: 0.5380 - val_custom_top_3_accuracy: 0.8251 - val_custom_top_5_accuracy: 0.9305 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 314s 47ms/step - loss: 1.1133 - custom_sparse_categorical_accuracy: 0.5408 - custom_top_3_accuracy: 0.8286 - custom_top_5_accuracy: 0.9329 - val_loss: 1.0936 - val_custom_sparse_categorical_accuracy: 0.5465 - val_custom_top_3_accuracy: 0.8337 - val_custom_top_5_accuracy: 0.9366 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 305s 46ms/step - loss: 1.0826 - custom_sparse_categorical_accuracy: 0.5501 - custom_top_3_accuracy: 0.8370 - custom_top_5_accuracy: 0.9382 - val_loss: 1.0733 - val_custom_sparse_categorical_accuracy: 0.5525 - val_custom_top_3_accuracy: 0.8394 - val_custom_top_5_accuracy: 0.9398 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 303s 45ms/step - loss: 1.0669 - custom_sparse_categorical_accuracy: 0.5551 - custom_top_3_accuracy: 0.8412 - custom_top_5_accuracy: 0.9410 - val_loss: 1.0643 - val_custom_sparse_categorical_accuracy: 0.5562 - val_custom_top_3_accuracy: 0.8417 - val_custom_top_5_accuracy: 0.9413 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 306s 46ms/step - loss: 1.0649 - custom_sparse_categorical_accuracy: 0.5556 - custom_top_3_accuracy: 0.8418 - custom_top_5_accuracy: 0.9414 - val_loss: 1.0609 - val_custom_sparse_categorical_accuracy: 0.5572 - val_custom_top_3_accuracy: 0.8429 - val_custom_top_5_accuracy: 0.9419 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 302s 45ms/step - loss: 1.0554 - custom_sparse_categorical_accuracy: 0.5591 - custom_top_3_accuracy: 0.8447 - custom_top_5_accuracy: 0.9430 - val_loss: 1.0549 - val_custom_sparse_categorical_accuracy: 0.5597 - val_custom_top_3_accuracy: 0.8445 - val_custom_top_5_accuracy: 0.9428 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 295s 44ms/step - loss: 1.0537 - custom_sparse_categorical_accuracy: 0.5596 - custom_top_3_accuracy: 0.8451 - custom_top_5_accuracy: 0.9434 - val_loss: 1.0543 - val_custom_sparse_categorical_accuracy: 0.5599 - val_custom_top_3_accuracy: 0.8447 - val_custom_top_5_accuracy: 0.9429 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 294s 44ms/step - loss: 1.0517 - custom_sparse_categorical_accuracy: 0.5603 - custom_top_3_accuracy: 0.8456 - custom_top_5_accuracy: 0.9437 - val_loss: 1.0534 - val_custom_sparse_categorical_accuracy: 0.5602 - val_custom_top_3_accuracy: 0.8449 - val_custom_top_5_accuracy: 0.9430 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 295s 44ms/step - loss: 1.0512 - custom_sparse_categorical_accuracy: 0.5605 - custom_top_3_accuracy: 0.8457 - custom_top_5_accuracy: 0.9437 - val_loss: 1.0533 - val_custom_sparse_categorical_accuracy: 0.5603 - val_custom_top_3_accuracy: 0.8449 - val_custom_top_5_accuracy: 0.9430 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_medium.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=custom_loss,\n",
        "                     metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                              CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                              CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_medium = model_medium.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_medium.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_medium.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_medium.save_weights(\"models/modeling/QBGPT/weights/model_medium/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw11bDzz4fye",
        "outputId": "2f2de2dc-6d84-4b33-d4ea-ffc718a02caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  4020480   \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  2795132   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6815612 (26.00 MB)\n",
            "Trainable params: 6815100 (26.00 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_medium.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS370fCo3pd-",
        "outputId": "ab0c75fc-90ff-4bcb-8570-092f9526a43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 540s 81ms/step - loss: 1.2288 - custom_sparse_categorical_accuracy: 0.5197 - custom_top_3_accuracy: 0.8041 - custom_top_5_accuracy: 0.9124 - val_loss: 1.1425 - val_custom_sparse_categorical_accuracy: 0.5335 - val_custom_top_3_accuracy: 0.8224 - val_custom_top_5_accuracy: 0.9287 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 342s 51ms/step - loss: 1.1009 - custom_sparse_categorical_accuracy: 0.5442 - custom_top_3_accuracy: 0.8319 - custom_top_5_accuracy: 0.9351 - val_loss: 1.1188 - val_custom_sparse_categorical_accuracy: 0.5416 - val_custom_top_3_accuracy: 0.8293 - val_custom_top_5_accuracy: 0.9331 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 326s 49ms/step - loss: 1.0705 - custom_sparse_categorical_accuracy: 0.5534 - custom_top_3_accuracy: 0.8404 - custom_top_5_accuracy: 0.9406 - val_loss: 1.0653 - val_custom_sparse_categorical_accuracy: 0.5554 - val_custom_top_3_accuracy: 0.8415 - val_custom_top_5_accuracy: 0.9412 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 322s 48ms/step - loss: 1.0529 - custom_sparse_categorical_accuracy: 0.5591 - custom_top_3_accuracy: 0.8453 - custom_top_5_accuracy: 0.9438 - val_loss: 1.0548 - val_custom_sparse_categorical_accuracy: 0.5586 - val_custom_top_3_accuracy: 0.8444 - val_custom_top_5_accuracy: 0.9431 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 324s 49ms/step - loss: 1.0486 - custom_sparse_categorical_accuracy: 0.5604 - custom_top_3_accuracy: 0.8466 - custom_top_5_accuracy: 0.9446 - val_loss: 1.0530 - val_custom_sparse_categorical_accuracy: 0.5590 - val_custom_top_3_accuracy: 0.8449 - val_custom_top_5_accuracy: 0.9434 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 320s 48ms/step - loss: 1.0384 - custom_sparse_categorical_accuracy: 0.5642 - custom_top_3_accuracy: 0.8497 - custom_top_5_accuracy: 0.9464 - val_loss: 1.0474 - val_custom_sparse_categorical_accuracy: 0.5615 - val_custom_top_3_accuracy: 0.8467 - val_custom_top_5_accuracy: 0.9443 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 320s 48ms/step - loss: 1.0363 - custom_sparse_categorical_accuracy: 0.5649 - custom_top_3_accuracy: 0.8503 - custom_top_5_accuracy: 0.9467 - val_loss: 1.0466 - val_custom_sparse_categorical_accuracy: 0.5618 - val_custom_top_3_accuracy: 0.8469 - val_custom_top_5_accuracy: 0.9445 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 319s 48ms/step - loss: 1.0343 - custom_sparse_categorical_accuracy: 0.5656 - custom_top_3_accuracy: 0.8509 - custom_top_5_accuracy: 0.9471 - val_loss: 1.0460 - val_custom_sparse_categorical_accuracy: 0.5621 - val_custom_top_3_accuracy: 0.8472 - val_custom_top_5_accuracy: 0.9446 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 320s 48ms/step - loss: 1.0337 - custom_sparse_categorical_accuracy: 0.5657 - custom_top_3_accuracy: 0.8511 - custom_top_5_accuracy: 0.9472 - val_loss: 1.0456 - val_custom_sparse_categorical_accuracy: 0.5621 - val_custom_top_3_accuracy: 0.8471 - val_custom_top_5_accuracy: 0.9446 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_large.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_large = model_large.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_large.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_large.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_large.save_weights(\"models/modeling/QBGPT/weights/model_large/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbV72hqP4cvw",
        "outputId": "4a73a080-bf62-4a30-d77d-142ccd6b32ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  9875968   \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  5579388   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15455356 (58.96 MB)\n",
            "Trainable params: 15454332 (58.95 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_large.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW-PxTSR52PA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}