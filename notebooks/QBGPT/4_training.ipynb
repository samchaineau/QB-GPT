{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gohwn7N_b3TF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "env = \"gdrive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if env != \"local\":\n",
        "  !git clone https://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@github.com/samchaineau/QB-GPT.git\n",
        "  import sys\n",
        "  sys.path.append(\"/content/QB-GPT/\")"
      ],
      "metadata": {
        "id": "iu7_UHcLMm0j",
        "outputId": "53dfdff7-9c28-46b7-d5f2-332d49c1fcaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'QB-GPT'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 88 (delta 34), reused 79 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (88/88), 110.66 KiB | 18.44 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Snyy4yk1MSuv",
        "outputId": "cfade475-7959-44eb-8998-118c52d90fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if env == \"local\":\n",
        "    os.chdir(\"/Users/samuel/Documents/GitHub/QB-GPT/\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    os.chdir(\"/content/gdrive/MyDrive/NFL_Challenge/QB-GPT/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dZk4pGEcWJn",
        "outputId": "16886921-37a4-48d9-bbc8-6abc4255c23e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_preprocessing', 'data_models', 'index', 'models']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZC8PlPFzcaLL"
      },
      "outputs": [],
      "source": [
        "training_data = tf.data.Dataset.load(\"data_models/QBGPT/train_tokens_NFL_GPT\")\n",
        "testing_data = tf.data.Dataset.load(\"data_models/QBGPT/test_tokens_NFL_GPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qHqmx-rHkAqZ"
      },
      "outputs": [],
      "source": [
        "train_length = [i for i,_ in enumerate(training_data)][-1] + 1\n",
        "test_length = [i for i,_ in enumerate(testing_data)][-1] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G74adOrokP8G",
        "outputId": "8c9d6c29-3c3f-4378-c02c-69f63213169c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train length is :  205851\n",
            "Test length is :  51463\n"
          ]
        }
      ],
      "source": [
        "print(\"Train length is : \", str(train_length))\n",
        "print(\"Test length is : \", str(test_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TisoHo24c-2_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "training_data = training_data.shuffle(train_length).batch(batch_size)\n",
        "testing_data = testing_data.shuffle(test_length).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxvvriqbc2f-"
      },
      "source": [
        "## Model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JLxwB6r9263v"
      },
      "outputs": [],
      "source": [
        "def insert_weights(df, w):\n",
        "  df[\"weights\"] = [w for i in range(df.shape[0])]\n",
        "  return df\n",
        "\n",
        "class_weights = pd.read_parquet(\"models/modeling/QBGPT/class_weights.parquet\")\n",
        "\n",
        "step_range = [(0, 10), (10, 100), (100, 1000), (1000, 10000), (10000, 50000), (50000, 100000), (100000, 300000), (300000, 500000), (500000, 1000000), (1000000, 10000000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qYgHoVIw-tHN"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "weights = dict(Counter(class_weights[\"Zone_ID\"].to_numpy()))\n",
        "weights_df = pd.DataFrame(np.array([[k, v] for k,v in weights.items()]), columns = [\"Class\", \"Count\"])\n",
        "\n",
        "weights_dict = {i : weights_df[(weights_df['Count'] > step_range[i][0]) & (weights_df['Count'] <= step_range[i][1])].reset_index(drop = True) for i in range(len(step_range))}\n",
        "w_dict = {0 : 1,\n",
        "          1 : 0.9,\n",
        "          2 : 0.8,\n",
        "          3 : 0.7,\n",
        "          4 : 0.6,\n",
        "          5 : 0.5,\n",
        "          6 : 0.4,\n",
        "          7 : 0.3,\n",
        "          8 : 0.2,\n",
        "          9 : 0.05,}\n",
        "\n",
        "weights_dict = {k:insert_weights(v, w_dict[k]) for k,v in weights_dict.items()}\n",
        "\n",
        "weights_df = pd.concat(list(weights_dict.values())).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "L4i4OY-o2PbX"
      },
      "outputs": [],
      "source": [
        "weights_inv = {v[0] : v[2] for v in weights_df.values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yrfmrVSWwKeI"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return 3e-3\n",
        "  elif (epoch >= 1) & (epoch < 2):\n",
        "    return 2e-3\n",
        "  elif (epoch >= 2) & (epoch < 3):\n",
        "    return 1e-3\n",
        "  elif (epoch >= 3) & (epoch < 5):\n",
        "    return 5e-4\n",
        "  elif (epoch >= 5) & (epoch < 7):\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 5e-5\n",
        "\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vZnjt9Sli6S9"
      },
      "outputs": [],
      "source": [
        "from models.modeling.QBGPT.models import QBGPT, LargeQBGPT, XLargeQBGPT\n",
        "from models.modeling.QBGPT.losses_and_metrics import CustomSparseCategoricalAccuracy, CustomTopKAccuracy, CustomSparseCategoricalCrossentropy\n",
        "\n",
        "moves_to_pred = 11164\n",
        "input_size = 11166\n",
        "starts_size = 1985\n",
        "scrimmage_size = 100\n",
        "positions_id = 29\n",
        "temp_ids = 52\n",
        "\n",
        "model_large = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 512,\n",
        "                    hidden_dim = 512,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_medium = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 256,\n",
        "                    hidden_dim = 256,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_small = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 128,\n",
        "                    hidden_dim = 128,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_tiny = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 64,\n",
        "                    hidden_dim = 64,\n",
        "                    to_pred_size = moves_to_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_tiny.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_tiny = model_tiny.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_tiny.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_tiny.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_tiny.save_weights(\"models/modeling/QBGPT/weights/model_tiny/QBGPT\")"
      ],
      "metadata": {
        "id": "2y_DOiMxN80M",
        "outputId": "ea27c38e-32cb-41df-f188-ad711a08cc22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 477s 70ms/step - loss: 1.3138 - custom_sparse_categorical_accuracy: 0.4932 - custom_top_3_accuracy: 0.7730 - custom_top_5_accuracy: 0.8867 - val_loss: 1.1638 - val_custom_sparse_categorical_accuracy: 0.5166 - val_custom_top_3_accuracy: 0.8041 - val_custom_top_5_accuracy: 0.9152 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 294s 44ms/step - loss: 1.1665 - custom_sparse_categorical_accuracy: 0.5177 - custom_top_3_accuracy: 0.8038 - custom_top_5_accuracy: 0.9146 - val_loss: 1.1311 - val_custom_sparse_categorical_accuracy: 0.5266 - val_custom_top_3_accuracy: 0.8136 - val_custom_top_5_accuracy: 0.9215 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 286s 43ms/step - loss: 1.1392 - custom_sparse_categorical_accuracy: 0.5261 - custom_top_3_accuracy: 0.8115 - custom_top_5_accuracy: 0.9199 - val_loss: 1.1106 - val_custom_sparse_categorical_accuracy: 0.5343 - val_custom_top_3_accuracy: 0.8199 - val_custom_top_5_accuracy: 0.9256 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 284s 42ms/step - loss: 1.1264 - custom_sparse_categorical_accuracy: 0.5305 - custom_top_3_accuracy: 0.8151 - custom_top_5_accuracy: 0.9222 - val_loss: 1.1009 - val_custom_sparse_categorical_accuracy: 0.5382 - val_custom_top_3_accuracy: 0.8226 - val_custom_top_5_accuracy: 0.9272 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 282s 42ms/step - loss: 1.1239 - custom_sparse_categorical_accuracy: 0.5311 - custom_top_3_accuracy: 0.8157 - custom_top_5_accuracy: 0.9227 - val_loss: 1.0999 - val_custom_sparse_categorical_accuracy: 0.5384 - val_custom_top_3_accuracy: 0.8231 - val_custom_top_5_accuracy: 0.9275 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 281s 42ms/step - loss: 1.1162 - custom_sparse_categorical_accuracy: 0.5342 - custom_top_3_accuracy: 0.8182 - custom_top_5_accuracy: 0.9241 - val_loss: 1.0939 - val_custom_sparse_categorical_accuracy: 0.5411 - val_custom_top_3_accuracy: 0.8249 - val_custom_top_5_accuracy: 0.9285 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 278s 41ms/step - loss: 1.1151 - custom_sparse_categorical_accuracy: 0.5345 - custom_top_3_accuracy: 0.8185 - custom_top_5_accuracy: 0.9243 - val_loss: 1.0932 - val_custom_sparse_categorical_accuracy: 0.5414 - val_custom_top_3_accuracy: 0.8251 - val_custom_top_5_accuracy: 0.9287 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 280s 41ms/step - loss: 1.1136 - custom_sparse_categorical_accuracy: 0.5351 - custom_top_3_accuracy: 0.8190 - custom_top_5_accuracy: 0.9246 - val_loss: 1.0924 - val_custom_sparse_categorical_accuracy: 0.5417 - val_custom_top_3_accuracy: 0.8255 - val_custom_top_5_accuracy: 0.9289 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 279s 41ms/step - loss: 1.1132 - custom_sparse_categorical_accuracy: 0.5352 - custom_top_3_accuracy: 0.8191 - custom_top_5_accuracy: 0.9247 - val_loss: 1.0925 - val_custom_sparse_categorical_accuracy: 0.5418 - val_custom_top_3_accuracy: 0.8254 - val_custom_top_5_accuracy: 0.9288 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return 3e-3\n",
        "  elif (epoch >= 1) & (epoch < 3):\n",
        "    return 2e-3\n",
        "  elif (epoch >= 3) & (epoch < 5):\n",
        "    return 1e-3\n",
        "\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "MJjIzFVOX15P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_tiny.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_tiny = model_tiny.fit(training_data, validation_data = testing_data, epochs=5, callbacks = [schedule])"
      ],
      "metadata": {
        "id": "Xl7JeSXhXzrb",
        "outputId": "c53dd104-b836-4f61-be1e-a6772c866950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6433/6433 [==============================] - 422s 63ms/step - loss: 1.3123 - custom_sparse_categorical_accuracy: 0.4932 - custom_top_3_accuracy: 0.7733 - custom_top_5_accuracy: 0.8874 - val_loss: 1.1639 - val_custom_sparse_categorical_accuracy: 0.5162 - val_custom_top_3_accuracy: 0.8046 - val_custom_top_5_accuracy: 0.9155 - lr: 0.0030\n",
            "Epoch 2/5\n",
            "6433/6433 [==============================] - 291s 44ms/step - loss: 1.1671 - custom_sparse_categorical_accuracy: 0.5175 - custom_top_3_accuracy: 0.8037 - custom_top_5_accuracy: 0.9149 - val_loss: 1.1325 - val_custom_sparse_categorical_accuracy: 0.5266 - val_custom_top_3_accuracy: 0.8134 - val_custom_top_5_accuracy: 0.9217 - lr: 0.0020\n",
            "Epoch 3/5\n",
            "6433/6433 [==============================] - 287s 43ms/step - loss: 1.1537 - custom_sparse_categorical_accuracy: 0.5212 - custom_top_3_accuracy: 0.8075 - custom_top_5_accuracy: 0.9175 - val_loss: 1.1232 - val_custom_sparse_categorical_accuracy: 0.5296 - val_custom_top_3_accuracy: 0.8165 - val_custom_top_5_accuracy: 0.9238 - lr: 0.0020\n",
            "Epoch 4/5\n",
            "6433/6433 [==============================] - 284s 42ms/step - loss: 1.1333 - custom_sparse_categorical_accuracy: 0.5280 - custom_top_3_accuracy: 0.8134 - custom_top_5_accuracy: 0.9213 - val_loss: 1.1078 - val_custom_sparse_categorical_accuracy: 0.5356 - val_custom_top_3_accuracy: 0.8209 - val_custom_top_5_accuracy: 0.9263 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "3845/6433 [================>.............] - ETA: 1:32 - loss: 1.1308 - custom_sparse_categorical_accuracy: 0.5285 - custom_top_3_accuracy: 0.8140 - custom_top_5_accuracy: 0.9218"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZEJDthj2iOT",
        "outputId": "1595bae9-e4e4-475f-f474-76204f5f316e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            " 113/6433 [..............................] - ETA: 58:34 - loss: 3.3350 - custom_sparse_categorical_accuracy: 0.3415 - custom_top_3_accuracy: 0.4864 - custom_top_5_accuracy: 0.5427"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m custom_loss \u001b[39m=\u001b[39m CustomSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, class_weights\u001b[39m=\u001b[39mweights_inv)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_small\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     loss\u001b[39m=\u001b[39mcustom_loss,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     metrics\u001b[39m=\u001b[39m[CustomSparseCategoricalAccuracy(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                              CustomTopKAccuracy(k\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcustom_top_3_accuracy\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                              CustomTopKAccuracy(k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcustom_top_5_accuracy\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history_small \u001b[39m=\u001b[39m model_small\u001b[39m.\u001b[39;49mfit(training_data, validation_data \u001b[39m=\u001b[39;49m testing_data, epochs\u001b[39m=\u001b[39;49m\u001b[39m9\u001b[39;49m, callbacks \u001b[39m=\u001b[39;49m [schedule])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(history_small\u001b[39m.\u001b[39mhistory)\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mmodels/modeling/history/training_history_model_small.csv\u001b[39m\u001b[39m\"\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/samuel/Documents/GitHub/QB-GPT/notebooks/QBGPT/4_training.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model_small\u001b[39m.\u001b[39msave_weights(\u001b[39m\"\u001b[39m\u001b[39mmodels/modeling/weights/QBGPT/model_small/QBGPT\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
            "File \u001b[0;32m~/anaconda3/envs/nflgpt/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_small.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_small = model_small.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_small.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_small.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_small.save_weights(\"models/modeling/QBGPT/weights/model_small/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSx5kt044i17",
        "outputId": "ab72053c-a3cc-4ed7-f952-3a5b8767533f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"qbgpt_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  1939584   \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  1440156   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3379740 (12.89 MB)\n",
            "Trainable params: 3379484 (12.89 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_small.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YARcSnUXUz1",
        "outputId": "db96f145-75dc-4607-e7aa-73cd8abab7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 472s 70ms/step - loss: 1.4208 - custom_sparse_categorical_accuracy: 0.5094 - custom_top_3_accuracy: 0.7895 - custom_top_5_accuracy: 0.9008 - val_loss: 1.2922 - val_custom_sparse_categorical_accuracy: 0.5306 - val_custom_top_3_accuracy: 0.8140 - val_custom_top_5_accuracy: 0.9213 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 316s 47ms/step - loss: 1.2714 - custom_sparse_categorical_accuracy: 0.5351 - custom_top_3_accuracy: 0.8196 - custom_top_5_accuracy: 0.9256 - val_loss: 1.2455 - val_custom_sparse_categorical_accuracy: 0.5413 - val_custom_top_3_accuracy: 0.8259 - val_custom_top_5_accuracy: 0.9298 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 310s 46ms/step - loss: 1.2320 - custom_sparse_categorical_accuracy: 0.5456 - custom_top_3_accuracy: 0.8300 - custom_top_5_accuracy: 0.9324 - val_loss: 1.2201 - val_custom_sparse_categorical_accuracy: 0.5490 - val_custom_top_3_accuracy: 0.8327 - val_custom_top_5_accuracy: 0.9340 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 307s 46ms/step - loss: 1.2130 - custom_sparse_categorical_accuracy: 0.5512 - custom_top_3_accuracy: 0.8352 - custom_top_5_accuracy: 0.9357 - val_loss: 1.2081 - val_custom_sparse_categorical_accuracy: 0.5531 - val_custom_top_3_accuracy: 0.8361 - val_custom_top_5_accuracy: 0.9360 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 305s 45ms/step - loss: 1.2081 - custom_sparse_categorical_accuracy: 0.5523 - custom_top_3_accuracy: 0.8363 - custom_top_5_accuracy: 0.9366 - val_loss: 1.2044 - val_custom_sparse_categorical_accuracy: 0.5540 - val_custom_top_3_accuracy: 0.8370 - val_custom_top_5_accuracy: 0.9368 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 305s 45ms/step - loss: 1.1944 - custom_sparse_categorical_accuracy: 0.5571 - custom_top_3_accuracy: 0.8405 - custom_top_5_accuracy: 0.9391 - val_loss: 1.1930 - val_custom_sparse_categorical_accuracy: 0.5581 - val_custom_top_3_accuracy: 0.8407 - val_custom_top_5_accuracy: 0.9389 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 304s 45ms/step - loss: 1.1895 - custom_sparse_categorical_accuracy: 0.5586 - custom_top_3_accuracy: 0.8421 - custom_top_5_accuracy: 0.9401 - val_loss: 1.1891 - val_custom_sparse_categorical_accuracy: 0.5591 - val_custom_top_3_accuracy: 0.8420 - val_custom_top_5_accuracy: 0.9398 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 302s 45ms/step - loss: 1.1856 - custom_sparse_categorical_accuracy: 0.5596 - custom_top_3_accuracy: 0.8433 - custom_top_5_accuracy: 0.9409 - val_loss: 1.1877 - val_custom_sparse_categorical_accuracy: 0.5594 - val_custom_top_3_accuracy: 0.8423 - val_custom_top_5_accuracy: 0.9400 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 301s 45ms/step - loss: 1.1844 - custom_sparse_categorical_accuracy: 0.5599 - custom_top_3_accuracy: 0.8436 - custom_top_5_accuracy: 0.9411 - val_loss: 1.1866 - val_custom_sparse_categorical_accuracy: 0.5597 - val_custom_top_3_accuracy: 0.8427 - val_custom_top_5_accuracy: 0.9403 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_medium.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=custom_loss,\n",
        "                     metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                              CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                              CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_medium = model_medium.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_medium.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_medium.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_medium.save_weights(\"models/modeling/QBGPT/weights/model_medium/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw11bDzz4fye",
        "outputId": "72f980f4-26b7-4447-eddb-7020a52e6849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"qbgpt_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_4 (Encoder)         multiple                  4337920   \n",
            "                                                                 \n",
            " dense_20 (Dense)            multiple                  2869148   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7207068 (27.49 MB)\n",
            "Trainable params: 7206556 (27.49 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_medium.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS370fCo3pd-",
        "outputId": "2fda58bc-b1c8-4932-eec5-3ed30e86659a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 555s 82ms/step - loss: 1.4149 - custom_sparse_categorical_accuracy: 0.5107 - custom_top_3_accuracy: 0.7911 - custom_top_5_accuracy: 0.9023 - val_loss: 1.2823 - val_custom_sparse_categorical_accuracy: 0.5320 - val_custom_top_3_accuracy: 0.8168 - val_custom_top_5_accuracy: 0.9239 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 344s 51ms/step - loss: 1.2584 - custom_sparse_categorical_accuracy: 0.5381 - custom_top_3_accuracy: 0.8231 - custom_top_5_accuracy: 0.9282 - val_loss: 1.2386 - val_custom_sparse_categorical_accuracy: 0.5431 - val_custom_top_3_accuracy: 0.8283 - val_custom_top_5_accuracy: 0.9313 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 329s 49ms/step - loss: 1.2175 - custom_sparse_categorical_accuracy: 0.5491 - custom_top_3_accuracy: 0.8339 - custom_top_5_accuracy: 0.9353 - val_loss: 1.2119 - val_custom_sparse_categorical_accuracy: 0.5505 - val_custom_top_3_accuracy: 0.8351 - val_custom_top_5_accuracy: 0.9358 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 332s 50ms/step - loss: 1.1967 - custom_sparse_categorical_accuracy: 0.5553 - custom_top_3_accuracy: 0.8397 - custom_top_5_accuracy: 0.9389 - val_loss: 1.1994 - val_custom_sparse_categorical_accuracy: 0.5547 - val_custom_top_3_accuracy: 0.8386 - val_custom_top_5_accuracy: 0.9378 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 328s 49ms/step - loss: 1.1914 - custom_sparse_categorical_accuracy: 0.5567 - custom_top_3_accuracy: 0.8411 - custom_top_5_accuracy: 0.9398 - val_loss: 1.1981 - val_custom_sparse_categorical_accuracy: 0.5552 - val_custom_top_3_accuracy: 0.8392 - val_custom_top_5_accuracy: 0.9381 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 330s 49ms/step - loss: 1.1783 - custom_sparse_categorical_accuracy: 0.5612 - custom_top_3_accuracy: 0.8448 - custom_top_5_accuracy: 0.9420 - val_loss: 1.1917 - val_custom_sparse_categorical_accuracy: 0.5577 - val_custom_top_3_accuracy: 0.8408 - val_custom_top_5_accuracy: 0.9390 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 328s 49ms/step - loss: 1.1761 - custom_sparse_categorical_accuracy: 0.5618 - custom_top_3_accuracy: 0.8455 - custom_top_5_accuracy: 0.9423 - val_loss: 1.1913 - val_custom_sparse_categorical_accuracy: 0.5574 - val_custom_top_3_accuracy: 0.8408 - val_custom_top_5_accuracy: 0.9391 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 323s 48ms/step - loss: 1.1736 - custom_sparse_categorical_accuracy: 0.5626 - custom_top_3_accuracy: 0.8462 - custom_top_5_accuracy: 0.9428 - val_loss: 1.1904 - val_custom_sparse_categorical_accuracy: 0.5579 - val_custom_top_3_accuracy: 0.8411 - val_custom_top_5_accuracy: 0.9393 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 324s 48ms/step - loss: 1.1730 - custom_sparse_categorical_accuracy: 0.5627 - custom_top_3_accuracy: 0.8463 - custom_top_5_accuracy: 0.9429 - val_loss: 1.1904 - val_custom_sparse_categorical_accuracy: 0.5580 - val_custom_top_3_accuracy: 0.8412 - val_custom_top_5_accuracy: 0.9393 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_large.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_large = model_large.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_large.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_large.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_large.save_weights(\"models/modeling/QBGPT/weights/model_large/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbV72hqP4cvw",
        "outputId": "31c6c766-cc0e-4a61-bcab-08c93ee892a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"qbgpt\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  10510848  \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  5727132   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16237980 (61.94 MB)\n",
            "Trainable params: 16236956 (61.94 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_large.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW-PxTSR52PA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}