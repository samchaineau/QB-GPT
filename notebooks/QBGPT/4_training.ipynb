{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gohwn7N_b3TF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "env = \"gdrive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if env != \"local\":\n",
        "  !git clone https://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@github.com/samchaineau/QB-GPT.git\n",
        "  import sys\n",
        "  sys.path.append(\"/content/QB-GPT/\")"
      ],
      "metadata": {
        "id": "iu7_UHcLMm0j",
        "outputId": "13679e04-e48e-4541-efd0-0f6907bdb7df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'QB-GPT'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 93 (delta 37), reused 77 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (93/93), 117.16 KiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Snyy4yk1MSuv",
        "outputId": "8f264962-0353-4447-abbe-412bd4072b46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "if env == \"local\":\n",
        "    os.chdir(\"/Users/samuel/Documents/GitHub/QB-GPT/\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    os.chdir(\"/content/gdrive/MyDrive/NFL_Challenge/QB-GPT/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dZk4pGEcWJn",
        "outputId": "10f46aaf-377b-459a-905c-92e17a62ec1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_preprocessing', 'data_models', 'index', 'models']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZC8PlPFzcaLL"
      },
      "outputs": [],
      "source": [
        "training_data = tf.data.Dataset.load(\"data_models/QBGPT/train_tokens_NFL_GPT\")\n",
        "testing_data = tf.data.Dataset.load(\"data_models/QBGPT/test_tokens_NFL_GPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qHqmx-rHkAqZ"
      },
      "outputs": [],
      "source": [
        "train_length = [i for i,_ in enumerate(training_data)][-1] + 1\n",
        "test_length = [i for i,_ in enumerate(testing_data)][-1] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G74adOrokP8G",
        "outputId": "9570f98d-e426-41d0-cf0b-59c609abca63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train length is :  205851\n",
            "Test length is :  51463\n"
          ]
        }
      ],
      "source": [
        "print(\"Train length is : \", str(train_length))\n",
        "print(\"Test length is : \", str(test_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TisoHo24c-2_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "training_data = training_data.shuffle(train_length).batch(batch_size)\n",
        "testing_data = testing_data.shuffle(test_length).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxvvriqbc2f-"
      },
      "source": [
        "## Model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JLxwB6r9263v"
      },
      "outputs": [],
      "source": [
        "def insert_weights(df, w):\n",
        "  df[\"weights\"] = [w for i in range(df.shape[0])]\n",
        "  return df\n",
        "\n",
        "class_weights = pd.read_parquet(\"models/modeling/QBGPT/class_weights.parquet\")\n",
        "\n",
        "step_range = [(0, 10), (10, 100), (100, 1000), (1000, 10000), (10000, 50000), (50000, 100000), (100000, 300000), (300000, 500000), (500000, 1000000), (1000000, 10000000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qYgHoVIw-tHN"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "weights = dict(Counter(class_weights[\"Zone_ID\"].to_numpy()))\n",
        "weights_df = pd.DataFrame(np.array([[k, v] for k,v in weights.items()]), columns = [\"Class\", \"Count\"])\n",
        "\n",
        "weights_dict = {i : weights_df[(weights_df['Count'] > step_range[i][0]) & (weights_df['Count'] <= step_range[i][1])].reset_index(drop = True) for i in range(len(step_range))}\n",
        "w_dict = {0 : 1,\n",
        "          1 : 0.9,\n",
        "          2 : 0.8,\n",
        "          3 : 0.7,\n",
        "          4 : 0.6,\n",
        "          5 : 0.5,\n",
        "          6 : 0.4,\n",
        "          7 : 0.3,\n",
        "          8 : 0.2,\n",
        "          9 : 0.05,}\n",
        "\n",
        "weights_dict = {k:insert_weights(v, w_dict[k]) for k,v in weights_dict.items()}\n",
        "\n",
        "weights_df = pd.concat(list(weights_dict.values())).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L4i4OY-o2PbX"
      },
      "outputs": [],
      "source": [
        "weights_inv = {v[0] : v[2] for v in weights_df.values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yrfmrVSWwKeI"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return 3e-3\n",
        "  elif (epoch >= 1) & (epoch < 2):\n",
        "    return 2e-3\n",
        "  elif (epoch >= 2) & (epoch < 3):\n",
        "    return 1e-3\n",
        "  elif (epoch >= 3) & (epoch < 5):\n",
        "    return 5e-4\n",
        "  elif (epoch >= 5) & (epoch < 7):\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 5e-5\n",
        "\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vZnjt9Sli6S9"
      },
      "outputs": [],
      "source": [
        "from models.modeling.QBGPT.models import QBGPT, LargeQBGPT, XLargeQBGPT\n",
        "from models.modeling.QBGPT.losses_and_metrics import CustomSparseCategoricalAccuracy, CustomTopKAccuracy, CustomSparseCategoricalCrossentropy\n",
        "\n",
        "moves_to_pred = 11164\n",
        "input_size = 11166\n",
        "starts_size = 1985\n",
        "scrimmage_size = 100\n",
        "positions_id = 29\n",
        "temp_ids = 52\n",
        "\n",
        "model_large = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 512,\n",
        "                    hidden_dim = 512,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_medium = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 256,\n",
        "                    hidden_dim = 256,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_small = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 128,\n",
        "                    hidden_dim = 128,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_tiny = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = 2,\n",
        "                    type_vocab_size = 3,\n",
        "                    playtype_vocab_size = 9,\n",
        "                    embedding_dim = 64,\n",
        "                    hidden_dim = 64,\n",
        "                    to_pred_size = moves_to_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_tiny.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_tiny = model_tiny.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_tiny.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_tiny.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_tiny.save_weights(\"models/modeling/QBGPT/weights/model_tiny/QBGPT\")"
      ],
      "metadata": {
        "id": "2y_DOiMxN80M",
        "outputId": "ea27c38e-32cb-41df-f188-ad711a08cc22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 477s 70ms/step - loss: 1.3138 - custom_sparse_categorical_accuracy: 0.4932 - custom_top_3_accuracy: 0.7730 - custom_top_5_accuracy: 0.8867 - val_loss: 1.1638 - val_custom_sparse_categorical_accuracy: 0.5166 - val_custom_top_3_accuracy: 0.8041 - val_custom_top_5_accuracy: 0.9152 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 294s 44ms/step - loss: 1.1665 - custom_sparse_categorical_accuracy: 0.5177 - custom_top_3_accuracy: 0.8038 - custom_top_5_accuracy: 0.9146 - val_loss: 1.1311 - val_custom_sparse_categorical_accuracy: 0.5266 - val_custom_top_3_accuracy: 0.8136 - val_custom_top_5_accuracy: 0.9215 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 286s 43ms/step - loss: 1.1392 - custom_sparse_categorical_accuracy: 0.5261 - custom_top_3_accuracy: 0.8115 - custom_top_5_accuracy: 0.9199 - val_loss: 1.1106 - val_custom_sparse_categorical_accuracy: 0.5343 - val_custom_top_3_accuracy: 0.8199 - val_custom_top_5_accuracy: 0.9256 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 284s 42ms/step - loss: 1.1264 - custom_sparse_categorical_accuracy: 0.5305 - custom_top_3_accuracy: 0.8151 - custom_top_5_accuracy: 0.9222 - val_loss: 1.1009 - val_custom_sparse_categorical_accuracy: 0.5382 - val_custom_top_3_accuracy: 0.8226 - val_custom_top_5_accuracy: 0.9272 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 282s 42ms/step - loss: 1.1239 - custom_sparse_categorical_accuracy: 0.5311 - custom_top_3_accuracy: 0.8157 - custom_top_5_accuracy: 0.9227 - val_loss: 1.0999 - val_custom_sparse_categorical_accuracy: 0.5384 - val_custom_top_3_accuracy: 0.8231 - val_custom_top_5_accuracy: 0.9275 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 281s 42ms/step - loss: 1.1162 - custom_sparse_categorical_accuracy: 0.5342 - custom_top_3_accuracy: 0.8182 - custom_top_5_accuracy: 0.9241 - val_loss: 1.0939 - val_custom_sparse_categorical_accuracy: 0.5411 - val_custom_top_3_accuracy: 0.8249 - val_custom_top_5_accuracy: 0.9285 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 278s 41ms/step - loss: 1.1151 - custom_sparse_categorical_accuracy: 0.5345 - custom_top_3_accuracy: 0.8185 - custom_top_5_accuracy: 0.9243 - val_loss: 1.0932 - val_custom_sparse_categorical_accuracy: 0.5414 - val_custom_top_3_accuracy: 0.8251 - val_custom_top_5_accuracy: 0.9287 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 280s 41ms/step - loss: 1.1136 - custom_sparse_categorical_accuracy: 0.5351 - custom_top_3_accuracy: 0.8190 - custom_top_5_accuracy: 0.9246 - val_loss: 1.0924 - val_custom_sparse_categorical_accuracy: 0.5417 - val_custom_top_3_accuracy: 0.8255 - val_custom_top_5_accuracy: 0.9289 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 279s 41ms/step - loss: 1.1132 - custom_sparse_categorical_accuracy: 0.5352 - custom_top_3_accuracy: 0.8191 - custom_top_5_accuracy: 0.9247 - val_loss: 1.0925 - val_custom_sparse_categorical_accuracy: 0.5418 - val_custom_top_3_accuracy: 0.8254 - val_custom_top_5_accuracy: 0.9288 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZEJDthj2iOT",
        "outputId": "1dbe93bb-3745-4d79-cb90-7cd12491b9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 498s 73ms/step - loss: 1.2629 - custom_sparse_categorical_accuracy: 0.5032 - custom_top_3_accuracy: 0.7853 - custom_top_5_accuracy: 0.8979 - val_loss: 1.1444 - val_custom_sparse_categorical_accuracy: 0.5230 - val_custom_top_3_accuracy: 0.8101 - val_custom_top_5_accuracy: 0.9196 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 306s 46ms/step - loss: 1.1351 - custom_sparse_categorical_accuracy: 0.5272 - custom_top_3_accuracy: 0.8129 - custom_top_5_accuracy: 0.9215 - val_loss: 1.1143 - val_custom_sparse_categorical_accuracy: 0.5332 - val_custom_top_3_accuracy: 0.8183 - val_custom_top_5_accuracy: 0.9252 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 300s 45ms/step - loss: 1.1083 - custom_sparse_categorical_accuracy: 0.5358 - custom_top_3_accuracy: 0.8204 - custom_top_5_accuracy: 0.9264 - val_loss: 1.0924 - val_custom_sparse_categorical_accuracy: 0.5406 - val_custom_top_3_accuracy: 0.8250 - val_custom_top_5_accuracy: 0.9294 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 295s 44ms/step - loss: 1.0951 - custom_sparse_categorical_accuracy: 0.5402 - custom_top_3_accuracy: 0.8242 - custom_top_5_accuracy: 0.9288 - val_loss: 1.0829 - val_custom_sparse_categorical_accuracy: 0.5441 - val_custom_top_3_accuracy: 0.8279 - val_custom_top_5_accuracy: 0.9312 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 295s 44ms/step - loss: 1.0924 - custom_sparse_categorical_accuracy: 0.5409 - custom_top_3_accuracy: 0.8249 - custom_top_5_accuracy: 0.9294 - val_loss: 1.0810 - val_custom_sparse_categorical_accuracy: 0.5445 - val_custom_top_3_accuracy: 0.8284 - val_custom_top_5_accuracy: 0.9316 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 294s 44ms/step - loss: 1.0843 - custom_sparse_categorical_accuracy: 0.5441 - custom_top_3_accuracy: 0.8274 - custom_top_5_accuracy: 0.9309 - val_loss: 1.0762 - val_custom_sparse_categorical_accuracy: 0.5467 - val_custom_top_3_accuracy: 0.8301 - val_custom_top_5_accuracy: 0.9324 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 293s 44ms/step - loss: 1.0831 - custom_sparse_categorical_accuracy: 0.5445 - custom_top_3_accuracy: 0.8277 - custom_top_5_accuracy: 0.9312 - val_loss: 1.0750 - val_custom_sparse_categorical_accuracy: 0.5471 - val_custom_top_3_accuracy: 0.8304 - val_custom_top_5_accuracy: 0.9327 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 292s 43ms/step - loss: 1.0816 - custom_sparse_categorical_accuracy: 0.5451 - custom_top_3_accuracy: 0.8283 - custom_top_5_accuracy: 0.9314 - val_loss: 1.0747 - val_custom_sparse_categorical_accuracy: 0.5472 - val_custom_top_3_accuracy: 0.8304 - val_custom_top_5_accuracy: 0.9327 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 291s 43ms/step - loss: 1.0811 - custom_sparse_categorical_accuracy: 0.5451 - custom_top_3_accuracy: 0.8283 - custom_top_5_accuracy: 0.9315 - val_loss: 1.0745 - val_custom_sparse_categorical_accuracy: 0.5473 - val_custom_top_3_accuracy: 0.8306 - val_custom_top_5_accuracy: 0.9328 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_small.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_small = model_small.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_small.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_small.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_small.save_weights(\"models/modeling/QBGPT/weights/model_small/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSx5kt044i17",
        "outputId": "32b28a6c-9c7b-46cc-e2fd-b88a48eb564d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  1939712   \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  1440156   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3379868 (12.89 MB)\n",
            "Trainable params: 3379612 (12.89 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_small.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YARcSnUXUz1",
        "outputId": "c5406246-5d3f-43a1-a38b-f6b126f50d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 523s 78ms/step - loss: 1.2466 - custom_sparse_categorical_accuracy: 0.5071 - custom_top_3_accuracy: 0.7899 - custom_top_5_accuracy: 0.9019 - val_loss: 1.1350 - val_custom_sparse_categorical_accuracy: 0.5266 - val_custom_top_3_accuracy: 0.8133 - val_custom_top_5_accuracy: 0.9222 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 318s 48ms/step - loss: 1.1222 - custom_sparse_categorical_accuracy: 0.5313 - custom_top_3_accuracy: 0.8167 - custom_top_5_accuracy: 0.9243 - val_loss: 1.0987 - val_custom_sparse_categorical_accuracy: 0.5374 - val_custom_top_3_accuracy: 0.8227 - val_custom_top_5_accuracy: 0.9283 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 308s 46ms/step - loss: 1.0912 - custom_sparse_categorical_accuracy: 0.5412 - custom_top_3_accuracy: 0.8250 - custom_top_5_accuracy: 0.9296 - val_loss: 1.0794 - val_custom_sparse_categorical_accuracy: 0.5449 - val_custom_top_3_accuracy: 0.8284 - val_custom_top_5_accuracy: 0.9317 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 306s 46ms/step - loss: 1.0758 - custom_sparse_categorical_accuracy: 0.5462 - custom_top_3_accuracy: 0.8294 - custom_top_5_accuracy: 0.9324 - val_loss: 1.0678 - val_custom_sparse_categorical_accuracy: 0.5488 - val_custom_top_3_accuracy: 0.8316 - val_custom_top_5_accuracy: 0.9336 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 304s 45ms/step - loss: 1.0715 - custom_sparse_categorical_accuracy: 0.5473 - custom_top_3_accuracy: 0.8306 - custom_top_5_accuracy: 0.9332 - val_loss: 1.0650 - val_custom_sparse_categorical_accuracy: 0.5492 - val_custom_top_3_accuracy: 0.8322 - val_custom_top_5_accuracy: 0.9342 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 300s 45ms/step - loss: 1.0620 - custom_sparse_categorical_accuracy: 0.5508 - custom_top_3_accuracy: 0.8336 - custom_top_5_accuracy: 0.9350 - val_loss: 1.0588 - val_custom_sparse_categorical_accuracy: 0.5519 - val_custom_top_3_accuracy: 0.8344 - val_custom_top_5_accuracy: 0.9353 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 301s 45ms/step - loss: 1.0601 - custom_sparse_categorical_accuracy: 0.5514 - custom_top_3_accuracy: 0.8341 - custom_top_5_accuracy: 0.9353 - val_loss: 1.0580 - val_custom_sparse_categorical_accuracy: 0.5522 - val_custom_top_3_accuracy: 0.8345 - val_custom_top_5_accuracy: 0.9354 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 302s 45ms/step - loss: 1.0585 - custom_sparse_categorical_accuracy: 0.5520 - custom_top_3_accuracy: 0.8346 - custom_top_5_accuracy: 0.9357 - val_loss: 1.0573 - val_custom_sparse_categorical_accuracy: 0.5525 - val_custom_top_3_accuracy: 0.8348 - val_custom_top_5_accuracy: 0.9356 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 300s 45ms/step - loss: 1.0580 - custom_sparse_categorical_accuracy: 0.5521 - custom_top_3_accuracy: 0.8348 - custom_top_5_accuracy: 0.9358 - val_loss: 1.0574 - val_custom_sparse_categorical_accuracy: 0.5524 - val_custom_top_3_accuracy: 0.8348 - val_custom_top_5_accuracy: 0.9357 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_medium.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=custom_loss,\n",
        "                     metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                              CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                              CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_medium = model_medium.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_medium.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_medium.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_medium.save_weights(\"models/modeling/QBGPT/weights/model_medium/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw11bDzz4fye",
        "outputId": "d4b8735b-ba3b-4e56-f507-e42e0e05ad07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  4338176   \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  2869148   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7207324 (27.49 MB)\n",
            "Trainable params: 7206812 (27.49 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_medium.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS370fCo3pd-",
        "outputId": "08ace502-c64d-40ce-dd01-bc27e606945d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 562s 84ms/step - loss: 1.2507 - custom_sparse_categorical_accuracy: 0.5066 - custom_top_3_accuracy: 0.7894 - custom_top_5_accuracy: 0.9015 - val_loss: 4.0362 - val_custom_sparse_categorical_accuracy: 0.2016 - val_custom_top_3_accuracy: 0.3051 - val_custom_top_5_accuracy: 0.3586 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 350s 52ms/step - loss: 1.1171 - custom_sparse_categorical_accuracy: 0.5326 - custom_top_3_accuracy: 0.8182 - custom_top_5_accuracy: 0.9253 - val_loss: 1.1034 - val_custom_sparse_categorical_accuracy: 0.5376 - val_custom_top_3_accuracy: 0.8224 - val_custom_top_5_accuracy: 0.9281 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 338s 51ms/step - loss: 1.0826 - custom_sparse_categorical_accuracy: 0.5431 - custom_top_3_accuracy: 0.8275 - custom_top_5_accuracy: 0.9315 - val_loss: 1.0749 - val_custom_sparse_categorical_accuracy: 0.5452 - val_custom_top_3_accuracy: 0.8297 - val_custom_top_5_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 337s 50ms/step - loss: 1.0660 - custom_sparse_categorical_accuracy: 0.5486 - custom_top_3_accuracy: 0.8325 - custom_top_5_accuracy: 0.9346 - val_loss: 1.0636 - val_custom_sparse_categorical_accuracy: 0.5493 - val_custom_top_3_accuracy: 0.8330 - val_custom_top_5_accuracy: 0.9349 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 336s 50ms/step - loss: 1.0616 - custom_sparse_categorical_accuracy: 0.5499 - custom_top_3_accuracy: 0.8337 - custom_top_5_accuracy: 0.9355 - val_loss: 1.0627 - val_custom_sparse_categorical_accuracy: 0.5494 - val_custom_top_3_accuracy: 0.8334 - val_custom_top_5_accuracy: 0.9351 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 331s 50ms/step - loss: 1.0511 - custom_sparse_categorical_accuracy: 0.5539 - custom_top_3_accuracy: 0.8371 - custom_top_5_accuracy: 0.9375 - val_loss: 1.0563 - val_custom_sparse_categorical_accuracy: 0.5521 - val_custom_top_3_accuracy: 0.8352 - val_custom_top_5_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 329s 49ms/step - loss: 1.0493 - custom_sparse_categorical_accuracy: 0.5544 - custom_top_3_accuracy: 0.8377 - custom_top_5_accuracy: 0.9378 - val_loss: 1.0556 - val_custom_sparse_categorical_accuracy: 0.5523 - val_custom_top_3_accuracy: 0.8355 - val_custom_top_5_accuracy: 0.9364 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 327s 49ms/step - loss: 1.0471 - custom_sparse_categorical_accuracy: 0.5553 - custom_top_3_accuracy: 0.8383 - custom_top_5_accuracy: 0.9382 - val_loss: 1.0551 - val_custom_sparse_categorical_accuracy: 0.5526 - val_custom_top_3_accuracy: 0.8357 - val_custom_top_5_accuracy: 0.9365 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 326s 49ms/step - loss: 1.0465 - custom_sparse_categorical_accuracy: 0.5554 - custom_top_3_accuracy: 0.8385 - custom_top_5_accuracy: 0.9384 - val_loss: 1.0548 - val_custom_sparse_categorical_accuracy: 0.5526 - val_custom_top_3_accuracy: 0.8357 - val_custom_top_5_accuracy: 0.9365 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_large.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_large = model_large.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_large.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_large.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_large.save_weights(\"models/modeling/QBGPT/weights/model_large/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbV72hqP4cvw",
        "outputId": "51ea6b82-56fa-4a5e-ca2a-a2a8485e0805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  10511360  \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  5727132   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16238492 (61.94 MB)\n",
            "Trainable params: 16237468 (61.94 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_large.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW-PxTSR52PA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}