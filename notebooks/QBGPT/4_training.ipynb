{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gohwn7N_b3TF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "env = \"gdrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu7_UHcLMm0j",
        "outputId": "5938ad50-b195-47dc-ba27-228b825425fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'QB-GPT' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "if env != \"local\":\n",
        "  !git clone https://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@github.com/samchaineau/QB-GPT.git\n",
        "  import sys\n",
        "  sys.path.append(\"/content/QB-GPT/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snyy4yk1MSuv",
        "outputId": "91224426-efba-44d4-e364-8b01eec5a31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if env == \"local\":\n",
        "    os.chdir(\"/Users/samuel/Documents/GitHub/QB-GPT/\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    os.chdir(\"/content/gdrive/MyDrive/NFL_Challenge/QB-GPT/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dZk4pGEcWJn",
        "outputId": "d6ad6db3-8df5-4b49-f610-b216d6263e0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_preprocessing', 'data_models', 'index', 'models', 'QBGPT.drawio']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZC8PlPFzcaLL"
      },
      "outputs": [],
      "source": [
        "training_data = tf.data.Dataset.load(\"data_models/QBGPT/train_tokens_NFL_GPT_v2\")\n",
        "testing_data = tf.data.Dataset.load(\"data_models/QBGPT/test_tokens_NFL_GPT_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qHqmx-rHkAqZ"
      },
      "outputs": [],
      "source": [
        "train_length = [i for i,_ in enumerate(training_data)][-1] + 1\n",
        "test_length = [i for i,_ in enumerate(testing_data)][-1] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G74adOrokP8G",
        "outputId": "12308d65-1a61-4283-a0cc-8abeaa4b4128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train length is :  201548\n",
            "Test length is :  50388\n"
          ]
        }
      ],
      "source": [
        "print(\"Train length is : \", str(train_length))\n",
        "print(\"Test length is : \", str(test_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TisoHo24c-2_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "training_data = training_data.shuffle(train_length).batch(batch_size)\n",
        "testing_data = testing_data.shuffle(test_length).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxvvriqbc2f-"
      },
      "source": [
        "## Model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JLxwB6r9263v"
      },
      "outputs": [],
      "source": [
        "def insert_weights(df, w):\n",
        "  df[\"weights\"] = [w for i in range(df.shape[0])]\n",
        "  return df\n",
        "\n",
        "class_weights = pd.read_parquet(\"models/modeling/QBGPT/class_weightsv2.parquet\")\n",
        "\n",
        "step_range = [(0, 10), (10, 100), (100, 1000), (1000, 10000), (10000, 50000), (50000, 100000), (100000, 300000), (300000, 500000), (500000, 1000000), (1000000, 10000000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qYgHoVIw-tHN"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "weights = dict(Counter(class_weights[\"Zone_ID\"].to_numpy()))\n",
        "weights_df = pd.DataFrame(np.array([[k, v] for k,v in weights.items()]), columns = [\"Class\", \"Count\"])\n",
        "\n",
        "weights_dict = {i : weights_df[(weights_df['Count'] > step_range[i][0]) & (weights_df['Count'] <= step_range[i][1])].reset_index(drop = True) for i in range(len(step_range))}\n",
        "w_dict = {0 : 1,\n",
        "          1 : 0.9,\n",
        "          2 : 0.8,\n",
        "          3 : 0.7,\n",
        "          4 : 0.6,\n",
        "          5 : 0.5,\n",
        "          6 : 0.4,\n",
        "          7 : 0.3,\n",
        "          8 : 0.2,\n",
        "          9 : 0.05,}\n",
        "\n",
        "weights_dict = {k:insert_weights(v, w_dict[k]) for k,v in weights_dict.items()}\n",
        "\n",
        "weights_df = pd.concat(list(weights_dict.values())).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L4i4OY-o2PbX"
      },
      "outputs": [],
      "source": [
        "weights_inv = {v[0] : v[2] for v in weights_df.values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXiP2NSCUGJv",
        "outputId": "6256b4ed-b017-4046-cfa8-58b94afb3735"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11169.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "max(weights_inv.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yrfmrVSWwKeI"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return 3e-3\n",
        "  elif (epoch >= 1) & (epoch < 2):\n",
        "    return 2e-3\n",
        "  elif (epoch >= 2) & (epoch < 3):\n",
        "    return 1e-3\n",
        "  elif (epoch >= 3) & (epoch < 5):\n",
        "    return 5e-4\n",
        "  elif (epoch >= 5) & (epoch < 7):\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 5e-5\n",
        "\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vZnjt9Sli6S9"
      },
      "outputs": [],
      "source": [
        "from models.modeling.QBGPT.models import QBGPT, LargeQBGPT, XLargeQBGPT\n",
        "from models.modeling.QBGPT.losses_and_metrics import CustomSparseCategoricalAccuracy, CustomTopKAccuracy, CustomSparseCategoricalCrossentropy\n",
        "\n",
        "moves_to_pred = 11170\n",
        "input_size = 11172\n",
        "starts_size = 1954\n",
        "scrimmage_size = 100\n",
        "positions_id = 29\n",
        "\n",
        "temp_ids = 52\n",
        "off_def_size = 2\n",
        "token_type_size = 3\n",
        "play_type_size = 9\n",
        "\n",
        "model_large = LargeQBGPT(input_vocab_size = input_size,\n",
        "                         positional_vocab_size = temp_ids,\n",
        "                         position_vocab_size=positions_id,\n",
        "                         start_vocab_size=starts_size,\n",
        "                         scrimmage_vocab_size=scrimmage_size,\n",
        "                         offdef_vocab_size = off_def_size,\n",
        "                         type_vocab_size = token_type_size,\n",
        "                         playtype_vocab_size = play_type_size,\n",
        "                         embedding_dim = 128,\n",
        "                         hidden_dim = 128,\n",
        "                         to_pred_size = moves_to_pred)\n",
        "\n",
        "model_medium = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 256,\n",
        "                    hidden_dim = 256,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_small = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 128,\n",
        "                    hidden_dim = 128,\n",
        "                    to_pred_size = moves_to_pred)\n",
        "\n",
        "model_tiny = QBGPT(input_vocab_size = input_size,\n",
        "                    positional_vocab_size = temp_ids,\n",
        "                    position_vocab_size=positions_id,\n",
        "                    start_vocab_size=starts_size,\n",
        "                    scrimmage_vocab_size=scrimmage_size,\n",
        "                    offdef_vocab_size = off_def_size,\n",
        "                    type_vocab_size = token_type_size,\n",
        "                    playtype_vocab_size = play_type_size,\n",
        "                    embedding_dim = 64,\n",
        "                    hidden_dim = 64,\n",
        "                    to_pred_size = moves_to_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y_DOiMxN80M",
        "outputId": "17be8096-f949-4397-bf95-5d575b0ff639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6299/6299 [==============================] - 630s 93ms/step - loss: 1.3630 - custom_sparse_categorical_accuracy: 0.4836 - custom_top_3_accuracy: 0.7639 - custom_top_5_accuracy: 0.8771 - val_loss: 1.1569 - val_custom_sparse_categorical_accuracy: 0.5153 - val_custom_top_3_accuracy: 0.8081 - val_custom_top_5_accuracy: 0.9186 - lr: 0.0030\n",
            "Epoch 2/9\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_tiny.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_tiny = model_tiny.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_tiny.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_tinyv2.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_tiny.save_weights(\"models/modeling/QBGPT/weights/model_tinyv2/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ziqs8ohmXuU",
        "outputId": "66542efb-3c9d-4266-ea3c-4ef54d3e5c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  832512    \n",
            "                                                                 \n",
            " dense_12 (Dense)            multiple                  706940    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1539452 (5.87 MB)\n",
            "Trainable params: 1539452 (5.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_tiny.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZEJDthj2iOT",
        "outputId": "fde8745c-6e0d-4761-ab67-f652d2b949ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6433/6433 [==============================] - 413s 61ms/step - loss: 1.2703 - custom_sparse_categorical_accuracy: 0.5145 - custom_top_3_accuracy: 0.7950 - custom_top_5_accuracy: 0.9023 - val_loss: 1.1154 - val_custom_sparse_categorical_accuracy: 0.5399 - val_custom_top_3_accuracy: 0.8274 - val_custom_top_5_accuracy: 0.9317 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6433/6433 [==============================] - 329s 49ms/step - loss: 1.1107 - custom_sparse_categorical_accuracy: 0.5415 - custom_top_3_accuracy: 0.8289 - custom_top_5_accuracy: 0.9329 - val_loss: 1.0827 - val_custom_sparse_categorical_accuracy: 0.5498 - val_custom_top_3_accuracy: 0.8365 - val_custom_top_5_accuracy: 0.9377 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6433/6433 [==============================] - 325s 48ms/step - loss: 1.0810 - custom_sparse_categorical_accuracy: 0.5504 - custom_top_3_accuracy: 0.8371 - custom_top_5_accuracy: 0.9384 - val_loss: 1.0632 - val_custom_sparse_categorical_accuracy: 0.5556 - val_custom_top_3_accuracy: 0.8422 - val_custom_top_5_accuracy: 0.9415 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6433/6433 [==============================] - 324s 48ms/step - loss: 1.0666 - custom_sparse_categorical_accuracy: 0.5551 - custom_top_3_accuracy: 0.8413 - custom_top_5_accuracy: 0.9411 - val_loss: 1.0532 - val_custom_sparse_categorical_accuracy: 0.5594 - val_custom_top_3_accuracy: 0.8451 - val_custom_top_5_accuracy: 0.9433 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6433/6433 [==============================] - 325s 49ms/step - loss: 1.0634 - custom_sparse_categorical_accuracy: 0.5559 - custom_top_3_accuracy: 0.8422 - custom_top_5_accuracy: 0.9418 - val_loss: 1.0519 - val_custom_sparse_categorical_accuracy: 0.5598 - val_custom_top_3_accuracy: 0.8455 - val_custom_top_5_accuracy: 0.9436 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6433/6433 [==============================] - 327s 49ms/step - loss: 1.0544 - custom_sparse_categorical_accuracy: 0.5592 - custom_top_3_accuracy: 0.8449 - custom_top_5_accuracy: 0.9434 - val_loss: 1.0458 - val_custom_sparse_categorical_accuracy: 0.5623 - val_custom_top_3_accuracy: 0.8473 - val_custom_top_5_accuracy: 0.9446 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6433/6433 [==============================] - 325s 49ms/step - loss: 1.0530 - custom_sparse_categorical_accuracy: 0.5596 - custom_top_3_accuracy: 0.8453 - custom_top_5_accuracy: 0.9436 - val_loss: 1.0454 - val_custom_sparse_categorical_accuracy: 0.5624 - val_custom_top_3_accuracy: 0.8475 - val_custom_top_5_accuracy: 0.9447 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6433/6433 [==============================] - 321s 48ms/step - loss: 1.0514 - custom_sparse_categorical_accuracy: 0.5602 - custom_top_3_accuracy: 0.8458 - custom_top_5_accuracy: 0.9440 - val_loss: 1.0446 - val_custom_sparse_categorical_accuracy: 0.5627 - val_custom_top_3_accuracy: 0.8477 - val_custom_top_5_accuracy: 0.9449 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6433/6433 [==============================] - 321s 48ms/step - loss: 1.0510 - custom_sparse_categorical_accuracy: 0.5603 - custom_top_3_accuracy: 0.8459 - custom_top_5_accuracy: 0.9440 - val_loss: 1.0443 - val_custom_sparse_categorical_accuracy: 0.5628 - val_custom_top_3_accuracy: 0.8478 - val_custom_top_5_accuracy: 0.9449 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_small.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_small = model_small.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_small.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_smallv2.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_small.save_weights(\"models/modeling/QBGPT/weights/model_smallv2/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSx5kt044i17",
        "outputId": "31a00822-030f-42b3-fc0d-316f74faae90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  1779712   \n",
            "                                                                 \n",
            " dense_9 (Dense)             multiple                  1403004   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3182716 (12.14 MB)\n",
            "Trainable params: 3182716 (12.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_small.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YARcSnUXUz1",
        "outputId": "f526f0f5-05ac-4e84-ac51-80426bacccdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6299/6299 [==============================] - 452s 69ms/step - loss: 1.2209 - custom_sparse_categorical_accuracy: 0.5201 - custom_top_3_accuracy: 0.8044 - custom_top_5_accuracy: 0.9090 - val_loss: 1.0290 - val_custom_sparse_categorical_accuracy: 0.5586 - val_custom_top_3_accuracy: 0.8519 - val_custom_top_5_accuracy: 0.9511 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6299/6299 [==============================] - 366s 56ms/step - loss: 0.9829 - custom_sparse_categorical_accuracy: 0.5759 - custom_top_3_accuracy: 0.8659 - custom_top_5_accuracy: 0.9581 - val_loss: 0.9478 - val_custom_sparse_categorical_accuracy: 0.5876 - val_custom_top_3_accuracy: 0.8754 - val_custom_top_5_accuracy: 0.9633 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6299/6299 [==============================] - 360s 55ms/step - loss: 0.9174 - custom_sparse_categorical_accuracy: 0.5995 - custom_top_3_accuracy: 0.8848 - custom_top_5_accuracy: 0.9676 - val_loss: 0.9012 - val_custom_sparse_categorical_accuracy: 0.6052 - val_custom_top_3_accuracy: 0.8891 - val_custom_top_5_accuracy: 0.9695 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6299/6299 [==============================] - 358s 55ms/step - loss: 0.8843 - custom_sparse_categorical_accuracy: 0.6119 - custom_top_3_accuracy: 0.8941 - custom_top_5_accuracy: 0.9719 - val_loss: 0.8773 - val_custom_sparse_categorical_accuracy: 0.6145 - val_custom_top_3_accuracy: 0.8957 - val_custom_top_5_accuracy: 0.9723 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6299/6299 [==============================] - 359s 55ms/step - loss: 0.8754 - custom_sparse_categorical_accuracy: 0.6151 - custom_top_3_accuracy: 0.8966 - custom_top_5_accuracy: 0.9731 - val_loss: 0.8728 - val_custom_sparse_categorical_accuracy: 0.6163 - val_custom_top_3_accuracy: 0.8970 - val_custom_top_5_accuracy: 0.9729 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6299/6299 [==============================] - 357s 55ms/step - loss: 0.8548 - custom_sparse_categorical_accuracy: 0.6232 - custom_top_3_accuracy: 0.9022 - custom_top_5_accuracy: 0.9755 - val_loss: 0.8596 - val_custom_sparse_categorical_accuracy: 0.6222 - val_custom_top_3_accuracy: 0.9004 - val_custom_top_5_accuracy: 0.9743 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6299/6299 [==============================] - 358s 55ms/step - loss: 0.8511 - custom_sparse_categorical_accuracy: 0.6246 - custom_top_3_accuracy: 0.9031 - custom_top_5_accuracy: 0.9758 - val_loss: 0.8582 - val_custom_sparse_categorical_accuracy: 0.6227 - val_custom_top_3_accuracy: 0.9008 - val_custom_top_5_accuracy: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6299/6299 [==============================] - 357s 55ms/step - loss: 0.8471 - custom_sparse_categorical_accuracy: 0.6263 - custom_top_3_accuracy: 0.9043 - custom_top_5_accuracy: 0.9763 - val_loss: 0.8562 - val_custom_sparse_categorical_accuracy: 0.6234 - val_custom_top_3_accuracy: 0.9014 - val_custom_top_5_accuracy: 0.9746 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6299/6299 [==============================] - 357s 55ms/step - loss: 0.8458 - custom_sparse_categorical_accuracy: 0.6268 - custom_top_3_accuracy: 0.9046 - custom_top_5_accuracy: 0.9764 - val_loss: 0.8557 - val_custom_sparse_categorical_accuracy: 0.6237 - val_custom_top_3_accuracy: 0.9015 - val_custom_top_5_accuracy: 0.9747 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_medium.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss=custom_loss,\n",
        "                     metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                              CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                              CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_medium = model_medium.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_medium.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_mediumv2.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_medium.save_weights(\"models/modeling/QBGPT/weights/model_mediumv2/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw11bDzz4fye",
        "outputId": "51efb8e1-06f3-4261-8b11-0ac1f63d84d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"qbgpt_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_3 (Encoder)         multiple                  4329216   \n",
            "                                                                 \n",
            " dense_19 (Dense)            multiple                  2870690   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7199906 (27.47 MB)\n",
            "Trainable params: 7199906 (27.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_medium.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return 5e-3\n",
        "  elif (epoch >= 1) & (epoch < 2):\n",
        "    return 2e-3\n",
        "  elif (epoch >= 2) & (epoch < 3):\n",
        "    return 1e-3\n",
        "  elif (epoch >= 3) & (epoch < 5):\n",
        "    return 5e-4\n",
        "  elif (epoch >= 5) & (epoch < 7):\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 5e-5\n",
        "\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "6J5M9UvmAsEF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS370fCo3pd-",
        "outputId": "5e4605c7-6776-43f1-ceac-fea3d42595f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "6299/6299 [==============================] - 441s 66ms/step - loss: 1.3164 - custom_sparse_categorical_accuracy: 0.4988 - custom_top_3_accuracy: 0.7756 - custom_top_5_accuracy: 0.8843 - val_loss: 1.0624 - val_custom_sparse_categorical_accuracy: 0.5469 - val_custom_top_3_accuracy: 0.8401 - val_custom_top_5_accuracy: 0.9438 - lr: 0.0030\n",
            "Epoch 2/9\n",
            "6299/6299 [==============================] - 359s 55ms/step - loss: 1.0360 - custom_sparse_categorical_accuracy: 0.5587 - custom_top_3_accuracy: 0.8487 - custom_top_5_accuracy: 0.9482 - val_loss: 0.9792 - val_custom_sparse_categorical_accuracy: 0.5766 - val_custom_top_3_accuracy: 0.8652 - val_custom_top_5_accuracy: 0.9584 - lr: 0.0020\n",
            "Epoch 3/9\n",
            "6299/6299 [==============================] - 356s 55ms/step - loss: 0.9712 - custom_sparse_categorical_accuracy: 0.5813 - custom_top_3_accuracy: 0.8681 - custom_top_5_accuracy: 0.9593 - val_loss: 0.9346 - val_custom_sparse_categorical_accuracy: 0.5936 - val_custom_top_3_accuracy: 0.8791 - val_custom_top_5_accuracy: 0.9654 - lr: 0.0010\n",
            "Epoch 4/9\n",
            "6299/6299 [==============================] - 355s 54ms/step - loss: 0.9401 - custom_sparse_categorical_accuracy: 0.5927 - custom_top_3_accuracy: 0.8774 - custom_top_5_accuracy: 0.9641 - val_loss: 0.9122 - val_custom_sparse_categorical_accuracy: 0.6017 - val_custom_top_3_accuracy: 0.8856 - val_custom_top_5_accuracy: 0.9685 - lr: 5.0000e-04\n",
            "Epoch 5/9\n",
            "6299/6299 [==============================] - 354s 54ms/step - loss: 0.9321 - custom_sparse_categorical_accuracy: 0.5954 - custom_top_3_accuracy: 0.8799 - custom_top_5_accuracy: 0.9653 - val_loss: 0.9061 - val_custom_sparse_categorical_accuracy: 0.6048 - val_custom_top_3_accuracy: 0.8873 - val_custom_top_5_accuracy: 0.9691 - lr: 5.0000e-04\n",
            "Epoch 6/9\n",
            "6299/6299 [==============================] - 353s 54ms/step - loss: 0.9136 - custom_sparse_categorical_accuracy: 0.6025 - custom_top_3_accuracy: 0.8852 - custom_top_5_accuracy: 0.9679 - val_loss: 0.8925 - val_custom_sparse_categorical_accuracy: 0.6101 - val_custom_top_3_accuracy: 0.8912 - val_custom_top_5_accuracy: 0.9707 - lr: 1.0000e-04\n",
            "Epoch 7/9\n",
            "6299/6299 [==============================] - 356s 54ms/step - loss: 0.9103 - custom_sparse_categorical_accuracy: 0.6037 - custom_top_3_accuracy: 0.8862 - custom_top_5_accuracy: 0.9683 - val_loss: 0.8905 - val_custom_sparse_categorical_accuracy: 0.6109 - val_custom_top_3_accuracy: 0.8919 - val_custom_top_5_accuracy: 0.9710 - lr: 1.0000e-04\n",
            "Epoch 8/9\n",
            "6299/6299 [==============================] - 353s 54ms/step - loss: 0.9069 - custom_sparse_categorical_accuracy: 0.6049 - custom_top_3_accuracy: 0.8872 - custom_top_5_accuracy: 0.9688 - val_loss: 0.8885 - val_custom_sparse_categorical_accuracy: 0.6117 - val_custom_top_3_accuracy: 0.8924 - val_custom_top_5_accuracy: 0.9712 - lr: 5.0000e-05\n",
            "Epoch 9/9\n",
            "6299/6299 [==============================] - 355s 54ms/step - loss: 0.9059 - custom_sparse_categorical_accuracy: 0.6053 - custom_top_3_accuracy: 0.8875 - custom_top_5_accuracy: 0.9689 - val_loss: 0.8880 - val_custom_sparse_categorical_accuracy: 0.6120 - val_custom_top_3_accuracy: 0.8926 - val_custom_top_5_accuracy: 0.9713 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "custom_loss = CustomSparseCategoricalCrossentropy(from_logits=True, class_weights=weights_inv)\n",
        "\n",
        "model_large.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss=custom_loss,\n",
        "                    metrics=[CustomSparseCategoricalAccuracy(),\n",
        "                             CustomTopKAccuracy(k=3, name='custom_top_3_accuracy'),\n",
        "                             CustomTopKAccuracy(k=5, name='custom_top_5_accuracy')])\n",
        "\n",
        "history_large = model_large.fit(training_data, validation_data = testing_data, epochs=9, callbacks = [schedule])\n",
        "\n",
        "pd.DataFrame(history_large.history).to_csv(\"models/modeling/QBGPT/history/training_history_model_largev2.csv\", index = False, sep = \";\")\n",
        "\n",
        "model_large.save_weights(\"models/modeling/QBGPT/weights/model_largev2/QBGPT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nbV72hqP4cvw",
        "outputId": "09b4800b-f9e5-4649-d31c-652b5c126640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"large_qbgpt\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_l (EncoderL)        multiple                  2148864   \n",
            "                                                                 \n",
            " dense_3 (Dense)             multiple                  1440930   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3589794 (13.69 MB)\n",
            "Trainable params: 3589794 (13.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_large.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW-PxTSR52PA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}