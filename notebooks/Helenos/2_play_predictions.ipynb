{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23522,"status":"ok","timestamp":1695750089313,"user":{"displayName":"sam Chain","userId":"00779398991030525753"},"user_tz":-120},"id":"BcuLdi7seAKr","outputId":"a57ae5af-106b-43d0-9d5a-816d53a8a4ca"},"outputs":[],"source":["import os\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","import polars as pl\n","import nfl_data_py as nfl\n","\n","env = \"local\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["if env == \"local\":\n","    os.chdir(\"/Users/samuel/Documents/GitHub/QB-GPT/\")\n","else:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","    os.chdir(\"/content/gdrive/MyDrive/NFL_Challenge/NFL-GPT/NFL data\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1695750225368,"user":{"displayName":"sam Chain","userId":"00779398991030525753"},"user_tz":-120},"id":"B2pOQ6qWeILn","outputId":"7e91fa10-a10c-4681-e348-1d5fed9420b1"},"outputs":[{"data":{"text/plain":["['data_models',\n"," '.DS_Store',\n"," 'app',\n"," 'LICENSE',\n"," 'models',\n"," 'README.md',\n"," '.gitignore',\n"," '.gitattributes',\n"," 'data_preprocessing',\n"," 'index',\n"," '.git',\n"," 'notebooks']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["os.listdir()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6338,"status":"ok","timestamp":1695750238260,"user":{"displayName":"sam Chain","userId":"00779398991030525753"},"user_tz":-120},"id":"n21dB8fmlAi_"},"outputs":[{"name":"stderr","output_type":"stream","text":["[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n","[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 5682129699177190627\n","[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n","[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 6191096588504482533\n"]}],"source":["training_data = tf.data.Dataset.load(\"data_models/Helenos_categ/train_play_prediction_reg\")\n","testing_data = tf.data.Dataset.load(\"data_models/Helenos_categ/test_play_prediction_reg\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1695750241105,"user":{"displayName":"sam Chain","userId":"00779398991030525753"},"user_tz":-120},"id":"8D31HaTelyvO","outputId":"1d3697f5-a143-43a1-9ee9-413564503b82"},"outputs":[{"name":"stderr","output_type":"stream","text":["[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n","[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 5682129699177190627\n","[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n","[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 6191096588504482533\n"]}],"source":["train_length = [i for i,_ in enumerate(training_data)][-1] + 1\n","test_length = [i for i,_ in enumerate(testing_data)][-1] + 1"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train length is :  290864\n","Test length is :  124656\n"]}],"source":["print(\"Train length is : \", str(train_length))\n","print(\"Test length is : \", str(test_length))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["batch_size = 32\n","\n","training_data = training_data.shuffle(train_length).batch(batch_size)\n","testing_data = testing_data.shuffle(test_length).batch(batch_size)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"EHNS1yT0p5sM"},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2d0eb77d0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from models.modeling.QBGPT.models import QBGPT, AttentionBlock\n","\n","moves_to_pred = 10876\n","input_size = 10878\n","starts_size = 1033\n","scrimmage_size = 100\n","positions_id = 29\n","temp_ids = 52\n","\n","off_def_size = 2\n","token_type_size = 2\n","play_type_size = 9\n","\n","\n","\n","model_tiny = QBGPT(input_vocab_size = input_size,\n","                    positional_vocab_size = temp_ids,\n","                    position_vocab_size=positions_id,\n","                    start_vocab_size=starts_size,\n","                    scrimmage_vocab_size=scrimmage_size,\n","                    offdef_vocab_size = off_def_size,\n","                    type_vocab_size = token_type_size,\n","                    playtype_vocab_size = play_type_size,\n","                    embedding_dim = 64,\n","                    hidden_dim = 64,\n","                    to_pred_size = moves_to_pred)\n","\n","\n","\n","model_tiny.load_weights(\"models/modeling/QBGPT/weights/model_tiny/QBGPT\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class DownEncoder(tf.keras.Model):\n","  def __init__(self, vocab_size : int, embedding_dim : int):\n","        super(DownEncoder, self).__init__()\n","\n","        self.Embedding = tf.keras.layers.Embedding(input_dim = vocab_size,\n","                                                   output_dim = embedding_dim)\n","\n","  def call(self, x):\n","    embed = self.Embedding(x[\"down_ID\"])\n","    return embed\n","\n","class SeasonEncoder(tf.keras.Model):\n","  def __init__(self, vocab_size : int, embedding_dim : int):\n","        super(SeasonEncoder, self).__init__()\n","\n","        self.Embedding = tf.keras.layers.Embedding(input_dim = vocab_size,\n","                                                   output_dim = embedding_dim)\n","\n","  def call(self, x):\n","    embed = self.Embedding(x[\"season_ID\"])\n","    return embed\n","\n","class TeamEncoder(tf.keras.Model):\n","  def __init__(self, vocab_size : int, embedding_dim : int):\n","        super(TeamEncoder, self).__init__()\n","\n","        self.Embedding = tf.keras.layers.Embedding(input_dim = vocab_size,\n","                                                   output_dim = embedding_dim)\n","\n","  def call(self, x):\n","    embed = self.Embedding(x[\"team_ID\"])\n","    return embed\n","\n","class PlayerEncoder(tf.keras.Model):\n","  def __init__(self, vocab_size : int, embedding_dim : int):\n","        super(PlayerEncoder, self).__init__()\n","\n","        self.Embedding = tf.keras.layers.Embedding(input_dim = vocab_size,\n","                                                   output_dim = embedding_dim)\n","\n","  def call(self, x):\n","    embed = self.Embedding(x[\"player_ids\"])\n","    return embed\n","\n","\n","class MetaEmbedding(tf.keras.Model):\n","  def __init__(self, \n","               team_vocab_size : int, \n","               player_vocab_size : int, \n","               season_vocab_size : int, \n","               down_vocab_size : int, \n","               embedding_dim : int):\n","        super(MetaEmbedding, self).__init__()\n","\n","        self.TeamEmbedding = TeamEncoder(vocab_size= team_vocab_size,\n","                                         embedding_dim=embedding_dim)\n","        self.PlayerEmbedding = PlayerEncoder(vocab_size= player_vocab_size,\n","                                             embedding_dim=embedding_dim)\n","        self.SeasonEmbedding = SeasonEncoder(vocab_size= season_vocab_size,\n","                                             embedding_dim=embedding_dim)\n","        self.DownEmbedding = DownEncoder(vocab_size= down_vocab_size,\n","                                         embedding_dim=embedding_dim)\n","        \n","        self.Add = tf.keras.layers.Add()\n","        \n","        self.Dense = tf.keras.layers.Dense(embedding_dim, activation = \"relu\")\n","\n","  def call(self, x):\n","    team_embed = self.TeamEmbedding(x)\n","    \n","    season_embed = self.SeasonEmbedding(x)\n","    down_embed = self.DownEmbedding(x)\n","    \n","    added = self.Add([team_embed, season_embed, down_embed])\n","    \n","    encoded = self.Dense(added)\n","    \n","    return encoded\n","\n","class Helenos(tf.keras.Model):\n","    def __init__(self, \n","                 team_vocab_size : int, \n","                 player_vocab_size : int,\n","                season_vocab_size : int,\n","                down_vocab_size : int, \n","                embedding_dim : int,\n","                encoder : tf.keras.Model,\n","                to_pred : int,\n","                activation : str):\n","        super(Helenos, self).__init__()\n","        \n","        self.Encoder = encoder\n","        self.MetaEmbedding = MetaEmbedding(team_vocab_size=team_vocab_size,\n","                                           player_vocab_size = player_vocab_size,\n","                                           season_vocab_size=season_vocab_size,\n","                                           down_vocab_size=down_vocab_size,\n","                                           embedding_dim=embedding_dim)\n","        \n","        self.Add = tf.keras.layers.Add()\n","        \n","        self.Concat = tf.keras.layers.Concatenate()\n","        \n","        self.Attention = AttentionBlock(num_heads=3,\n","                                        hidden_dim=256,\n","                                        output_dim=embedding_dim)\n","        \n","        self.Dense = tf.keras.layers.Dense(256, activation = \"gelu\")\n","        \n","        self.Pred = tf.keras.layers.Dense(to_pred, activation = activation)\n","        \n","    \n","    def call(self, x):\n","        encoded_qb_off = self.Encoder(x[\"off\"])\n","        encoded_meta_off = self.MetaEmbedding(x[\"off\"])\n","        encoded_off = self.Add([encoded_qb_off, encoded_meta_off])\n","        \n","        encoded_qb_def = self.Encoder(x[\"def\"])\n","        encoded_meta_def = self.MetaEmbedding(x[\"def\"])\n","        encoded_def = self.Add([encoded_qb_def, encoded_meta_def])\n","        \n","        logits_off = self.Attention(encoded_off, x[\"off\"][\"pos_ids\"], x[\"off\"][\"attention_mask\"])\n","        logits_def = self.Attention(encoded_def, x[\"def\"][\"pos_ids\"], x[\"def\"][\"attention_mask\"])\n","        \n","        logits = self.Concat([logits_off, logits_def])\n","        \n","        densed = self.Dense(logits)\n","        \n","        preds = self.Pred(densed)\n","        \n","        prediction = tf.reduce_mean(preds, axis = -2)\n","        \n","        return prediction"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["model = Helenos(team_vocab_size=32,\n","                player_vocab_size=21506,\n","                season_vocab_size= 7,\n","                down_vocab_size= 5,\n","                embedding_dim= 64,\n","                encoder = model_tiny.Encoder,\n","                to_pred=200,\n","                activation= \"linear\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["model.Encoder.trainable = True"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n","WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n","2023-10-04 00:52:10.369873: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 185271 of 290864\n"]},{"name":"stdout","output_type":"stream","text":["  10/9090 [..............................] - ETA: 2:03 - loss: 39177624.0000 - mean_absolute_error: 5.5607 - mean_squared_error: 87.5429  "]},{"name":"stderr","output_type":"stream","text":["2023-10-04 00:52:16.248005: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"]},{"name":"stdout","output_type":"stream","text":["9090/9090 [==============================] - 202s 20ms/step - loss: 693961.6250 - mean_absolute_error: 6.2612 - mean_squared_error: 106.0727 - val_loss: 717676.8750 - val_mean_absolute_error: 6.2591 - val_mean_squared_error: 106.1083\n"]}],"source":["model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                    loss= tf.keras.losses.MeanAbsolutePercentageError(),\n","                    metrics=[tf.keras.metrics.MeanAbsoluteError(),\n","                             tf.keras.metrics.MeanSquaredError()])\n","\n","\n","history_small = model.fit(training_data, validation_data = testing_data, epochs=1)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1/1 [==============================] - 0s 257ms/step\n","1\n","1/1 [==============================] - 0s 29ms/step\n","2\n","1/1 [==============================] - 0s 28ms/step\n","3\n","1/1 [==============================] - 0s 27ms/step\n","4\n","1/1 [==============================] - 0s 29ms/step\n","5\n","1/1 [==============================] - 0s 27ms/step\n","6\n","1/1 [==============================] - 0s 27ms/step\n","7\n","1/1 [==============================] - 0s 27ms/step\n","8\n","1/1 [==============================] - 0s 26ms/step\n","9\n","1/1 [==============================] - 0s 27ms/step\n","10\n","1/1 [==============================] - 0s 27ms/step\n","11\n","1/1 [==============================] - 0s 26ms/step\n","12\n","1/1 [==============================] - 0s 27ms/step\n","13\n","1/1 [==============================] - 0s 28ms/step\n","14\n","1/1 [==============================] - 0s 27ms/step\n","15\n","1/1 [==============================] - 0s 26ms/step\n","16\n","1/1 [==============================] - 0s 25ms/step\n","17\n","1/1 [==============================] - 0s 27ms/step\n","18\n","1/1 [==============================] - 0s 26ms/step\n","19\n","1/1 [==============================] - 0s 28ms/step\n","20\n","1/1 [==============================] - 0s 26ms/step\n","21\n","1/1 [==============================] - 0s 25ms/step\n","22\n","1/1 [==============================] - 0s 29ms/step\n","23\n","1/1 [==============================] - 0s 27ms/step\n","24\n","1/1 [==============================] - 0s 26ms/step\n","25\n","1/1 [==============================] - 0s 25ms/step\n","26\n","1/1 [==============================] - 0s 27ms/step\n","27\n","1/1 [==============================] - 0s 27ms/step\n","28\n","1/1 [==============================] - 0s 26ms/step\n","29\n","1/1 [==============================] - 0s 28ms/step\n","30\n","1/1 [==============================] - 0s 24ms/step\n","31\n","1/1 [==============================] - 0s 29ms/step\n","32\n","1/1 [==============================] - 0s 28ms/step\n","33\n","1/1 [==============================] - 0s 25ms/step\n","34\n","1/1 [==============================] - 0s 26ms/step\n","35\n","1/1 [==============================] - 0s 25ms/step\n","36\n","1/1 [==============================] - 0s 26ms/step\n","37\n","1/1 [==============================] - 0s 28ms/step\n","38\n","1/1 [==============================] - 0s 26ms/step\n","39\n","1/1 [==============================] - 0s 26ms/step\n","40\n","1/1 [==============================] - 0s 25ms/step\n","41\n","1/1 [==============================] - 0s 25ms/step\n","42\n","1/1 [==============================] - 0s 27ms/step\n","43\n","1/1 [==============================] - 0s 25ms/step\n","44\n","1/1 [==============================] - 0s 25ms/step\n","45\n","1/1 [==============================] - 0s 24ms/step\n","46\n","1/1 [==============================] - 0s 25ms/step\n","47\n","1/1 [==============================] - 0s 25ms/step\n","48\n","1/1 [==============================] - 0s 28ms/step\n","49\n","1/1 [==============================] - 0s 26ms/step\n","50\n","1/1 [==============================] - 0s 25ms/step\n"]}],"source":["preds = []\n","\n","i = 0\n","\n","for x,y in testing_data:\n","    print(i)\n","    prediction = model.predict(x)\n","    preds.append(prediction)    \n","    i+= 1\n","    if i > 50:\n","        break"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["0.049766496"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["np.max(np.vstack(preds))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["-0.039297324"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["np.min(np.vstack(preds))"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["0.00011544645"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(np.vstack(preds))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOdfJoNF73jOSn/+XfcVm3w","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
