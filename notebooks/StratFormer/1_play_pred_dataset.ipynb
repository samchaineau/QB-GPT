{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "env = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    os.chdir(\"/Users/samuel/Documents/GitHub/QB-GPT/\")\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/MyDrive/NFL_Challenge/NFL-GPT/NFL data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2023 done.\n",
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "years_to_get = [2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "season_data = pl.from_pandas(nfl.import_pbp_data(years_to_get))\n",
    "rosters = pl.from_pandas(nfl.import_seasonal_rosters(years_to_get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_index = pl.read_parquet(\"index/plays_index.parquet\")\n",
    "positions_index = pl.read_parquet(\"index/positions_index.parquet\")\n",
    "OL_df = pl.DataFrame({\"position\" : [\"OL\"],\n",
    "                      \"position_ID\" : [27],\n",
    "                      \"Cat\" : [\"Pos\"]})\n",
    "\n",
    "new_positions_index = pl.concat([positions_index, OL_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_index = (season_data.\n",
    "              select(\"home_team\").\n",
    "              rename({\"home_team\" : \"team\"}).\n",
    "              unique().\n",
    "              with_columns(pl.when(pl.col(\"team\") == \"OAK\").\n",
    "                           then(pl.lit(\"LV\")).\n",
    "                           otherwise(pl.col(\"team\")).\n",
    "                           alias(\"team\")).\n",
    "              with_columns(pl.arange(0, 32).alias(\"team_ID\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "yards_index = (pl.DataFrame({\"yards_gained\" : range(-99, 100), \n",
    "                            \"yard_ID\" : range(0, 199)}).\n",
    "                with_columns(pl.col(\"yards_gained\").cast(pl.Int32)).\n",
    "                with_columns(pl.col(\"yard_ID\").cast(pl.Int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_index = (pl.DataFrame({\"season\" : [2017, 2018, 2019, 2020, 2021, 2022, 2023], \n",
    "                            \"season_ID\" : [0, 1, 2, 3, 4, 5, 6]}).\n",
    "                with_columns(pl.col(\"season\").cast(pl.Int64)).\n",
    "                with_columns(pl.col(\"season_ID\").cast(pl.Int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_531, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>season</th><th>position</th><th>player_id</th><th>player_ID</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>2017</td><td>&quot;QB&quot;</td><td>&quot;00-0026898&quot;</td><td>0</td></tr><tr><td>2018</td><td>&quot;QB&quot;</td><td>&quot;00-0026898&quot;</td><td>0</td></tr><tr><td>2022</td><td>&quot;DB&quot;</td><td>&quot;00-0036147&quot;</td><td>1</td></tr><tr><td>2023</td><td>&quot;DB&quot;</td><td>&quot;00-0036147&quot;</td><td>1</td></tr><tr><td>2021</td><td>&quot;DB&quot;</td><td>&quot;00-0036147&quot;</td><td>1</td></tr><tr><td>2020</td><td>&quot;DB&quot;</td><td>&quot;00-0036147&quot;</td><td>1</td></tr><tr><td>2020</td><td>&quot;TE&quot;</td><td>&quot;00-0035756&quot;</td><td>2</td></tr><tr><td>2022</td><td>&quot;QB&quot;</td><td>&quot;00-0037175&quot;</td><td>3</td></tr><tr><td>2023</td><td>&quot;QB&quot;</td><td>&quot;00-0037175&quot;</td><td>3</td></tr><tr><td>2018</td><td>&quot;WR&quot;</td><td>&quot;00-0031801&quot;</td><td>4</td></tr><tr><td>2017</td><td>&quot;WR&quot;</td><td>&quot;00-0031801&quot;</td><td>4</td></tr><tr><td>2023</td><td>&quot;K&quot;</td><td>&quot;00-0038748&quot;</td><td>5</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2017</td><td>&quot;TE&quot;</td><td>&quot;00-0029793&quot;</td><td>7222</td></tr><tr><td>2018</td><td>&quot;DB&quot;</td><td>&quot;00-0033558&quot;</td><td>7223</td></tr><tr><td>2017</td><td>&quot;DB&quot;</td><td>&quot;00-0033558&quot;</td><td>7223</td></tr><tr><td>2017</td><td>&quot;DL&quot;</td><td>&quot;00-0032703&quot;</td><td>7224</td></tr><tr><td>2023</td><td>&quot;WR&quot;</td><td>&quot;00-0037570&quot;</td><td>7225</td></tr><tr><td>2022</td><td>&quot;WR&quot;</td><td>&quot;00-0037570&quot;</td><td>7225</td></tr><tr><td>2022</td><td>&quot;DL&quot;</td><td>&quot;00-0036420&quot;</td><td>7226</td></tr><tr><td>2020</td><td>&quot;DL&quot;</td><td>&quot;00-0036420&quot;</td><td>7226</td></tr><tr><td>2021</td><td>&quot;DL&quot;</td><td>&quot;00-0036420&quot;</td><td>7226</td></tr><tr><td>2023</td><td>&quot;DL&quot;</td><td>&quot;00-0036420&quot;</td><td>7226</td></tr><tr><td>2017</td><td>&quot;DB&quot;</td><td>&quot;00-0033313&quot;</td><td>7227</td></tr><tr><td>2018</td><td>&quot;DB&quot;</td><td>&quot;00-0033313&quot;</td><td>7227</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_531, 4)\n",
       "┌────────┬──────────┬────────────┬───────────┐\n",
       "│ season ┆ position ┆ player_id  ┆ player_ID │\n",
       "│ ---    ┆ ---      ┆ ---        ┆ ---       │\n",
       "│ i32    ┆ str      ┆ str        ┆ i64       │\n",
       "╞════════╪══════════╪════════════╪═══════════╡\n",
       "│ 2017   ┆ QB       ┆ 00-0026898 ┆ 0         │\n",
       "│ 2018   ┆ QB       ┆ 00-0026898 ┆ 0         │\n",
       "│ 2022   ┆ DB       ┆ 00-0036147 ┆ 1         │\n",
       "│ 2023   ┆ DB       ┆ 00-0036147 ┆ 1         │\n",
       "│ …      ┆ …        ┆ …          ┆ …         │\n",
       "│ 2021   ┆ DL       ┆ 00-0036420 ┆ 7226      │\n",
       "│ 2023   ┆ DL       ┆ 00-0036420 ┆ 7226      │\n",
       "│ 2017   ┆ DB       ┆ 00-0033313 ┆ 7227      │\n",
       "│ 2018   ┆ DB       ┆ 00-0033313 ┆ 7227      │\n",
       "└────────┴──────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosters_index = (rosters.\n",
    "                 select(\"season\", \"team\", \"position\", \"player_name\", \"jersey_number\", \"player_id\").\n",
    "                 unique().\n",
    "                 with_columns(pl.col(\"team\").str.replace(\"OAK\", \"LV\")).\n",
    "                 with_columns(pl.when(pl.col(\"jersey_number\").is_null()).\n",
    "                              then(pl.lit(0.0)).\n",
    "                              otherwise(pl.col(\"jersey_number\")).\n",
    "                              alias(\"jersey_number\")))\n",
    "\n",
    "sub_index = (rosters_index.\n",
    "             select(\"player_id\").\n",
    "             unique().\n",
    "             with_columns(pl.arange(0, 7228).alias(\"player_ID\")))\n",
    "\n",
    "rosters_index = (rosters_index.\n",
    "                 join(sub_index,\n",
    "                      on = [\"player_id\"],\n",
    "                      how = \"left\").\n",
    "                 select(\"season\", \"position\", \"player_id\", \"player_ID\").\n",
    "                 unique())\n",
    "\n",
    "rosters_index.sort(\"player_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = (season_data.\n",
    "             select(\"season\", \"old_game_id\", \"play_id\", \"home_team\", \"away_team\", \"posteam\", \"defteam\", \"down\", \"offense_players\", \"defense_players\", \"play_type\", \"yards_gained\").\n",
    "             filter(pl.col(\"play_type\").is_not_null()).\n",
    "             filter(pl.col(\"play_type\") != \"no_play\").\n",
    "             filter(pl.col(\"offense_players\") != \"\").\n",
    "             with_columns(pl.when(pl.col(\"down\").is_null()).\n",
    "                          then(pl.lit(0.0)).\n",
    "                          otherwise(pl.col(\"down\")).\n",
    "                          alias(\"down\")).\n",
    "             filter(pl.col(\"play_type\").\n",
    "                    is_in([\"run\", \"pass\"])).\n",
    "             with_columns(pl.when(pl.col(\"yards_gained\") > 0).\n",
    "                          then(pl.lit(1.0)).\n",
    "                          otherwise(pl.lit(0.0)).\n",
    "                          alias(\"Success\")).\n",
    "             melt(id_vars = [\"season\", \"old_game_id\", \"play_id\", \"home_team\", \"away_team\", \"posteam\", \"defteam\", \"down\", \"play_type\", \"yards_gained\", \"Success\"], \n",
    "                  value_vars = [\"offense_players\", \"defense_players\"],\n",
    "                  variable_name = \"team\",\n",
    "                  value_name = \"players\").\n",
    "             with_columns(pl.col(\"players\").str.split(\";\")).\n",
    "             explode(\"players\").\n",
    "             rename({\"players\" : \"player_id\"}).\n",
    "             join(rosters.\n",
    "                  select(\"season\", \"player_id\", \"depth_chart_position\").\n",
    "                  with_columns(pl.col(\"season\").cast(pl.Int64)).\n",
    "                  rename({\"depth_chart_position\" : \"position\"}).\n",
    "                  unique(),\n",
    "                  how = \"left\",\n",
    "                  on = [\"season\", \"player_id\"]).\n",
    "             with_columns(pl.col(\"team\").str.replace(\"_players\", \"\")).\n",
    "             filter(pl.col(\"position\").is_not_null()).\n",
    "             rename({\"team\" : \"OffDef\"}).\n",
    "             with_columns(pl.when(pl.col(\"OffDef\") == \"offense\").\n",
    "                          then(pl.col(\"posteam\")).\n",
    "                          otherwise(pl.col(\"defteam\")).\n",
    "                          alias(\"team\")).\n",
    "             drop(\"home_team\", \"away_team\", \"posteam\", \"defteam\").\n",
    "             with_columns(pl.when(pl.col(\"team\") == \"OAK\").\n",
    "                          then(pl.lit(\"LV\")).\n",
    "                          otherwise(pl.col(\"team\")).\n",
    "                          alias(\"team\")).\n",
    "             join(rosters_index.\n",
    "                  select(\"season\", \"player_id\", \"player_ID\").\n",
    "                  with_columns(pl.col(\"season\").cast(pl.Int64)),\n",
    "                  on = [\"season\", \"player_id\"],\n",
    "                  how = \"left\").\n",
    "             with_columns(pl.col(\"player_ID\").cumcount().over(\"player_ID\").alias(\"count\")).\n",
    "             with_columns(pl.when(pl.col(\"count\") < 25).\n",
    "              then(pl.lit(7228)).\n",
    "              otherwise(pl.col(\"player_ID\")).\n",
    "              alias(\"player_ID\")).\n",
    "             drop(\"count\", \"player_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = (spec_data.\n",
    "               join(new_positions_index.\n",
    "                    drop(\"Cat\"), \n",
    "                    on = \"position\",\n",
    "                    how = \"left\").\n",
    "               drop(\"position\").\n",
    "               group_by(\"season\", \"old_game_id\", \"play_id\", \"team\", \"OffDef\", \"down\", \"play_type\", \"yards_gained\", \"Success\").\n",
    "               agg(pl.col(\"position_ID\"),\n",
    "                    pl.col(\"player_ID\")).\n",
    "               with_columns(pl.when(pl.col(\"OffDef\") == \"offense\").\n",
    "                              then(pl.lit(1)).\n",
    "                              otherwise(pl.lit(0)).\n",
    "                              alias(\"OffDef_ID\")).\n",
    "               drop(\"OffDef\").\n",
    "               join(plays_index.\n",
    "                    rename({\"PlayType\" : \"play_type\"}),\n",
    "                    on = \"play_type\",\n",
    "                    how = \"left\").\n",
    "               drop(\"play_type\").\n",
    "               join(team_index,\n",
    "                    on = \"team\",\n",
    "                    how = \"left\").\n",
    "               drop(\"team\").\n",
    "               with_columns(pl.col(\"down\").cast(pl.Int32).alias(\"down_ID\")).\n",
    "               drop(\"down\").\n",
    "               rename({\"old_game_id\" : \"gameId\",\n",
    "                         \"play_id\" : \"playId\"}).\n",
    "               with_columns(pl.col(\"position_ID\").list.lengths().alias(\"Length\")).\n",
    "               filter(pl.col(\"Length\") == 11).\n",
    "               drop(\"Length\").\n",
    "               with_columns(pl.col(\"gameId\").cast(pl.Int32)).\n",
    "               with_columns(pl.col(\"playId\").cast(pl.Int32)).\n",
    "               with_columns(pl.col(\"yards_gained\").cast(pl.Int32)).\n",
    "               join(season_index, \n",
    "                    on = \"season\",\n",
    "                    how = \"left\").\n",
    "               drop(\"season\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = (spec_data.\n",
    "            select(\"gameId\", \"playId\", \"OffDef_ID\").\n",
    "            unique().\n",
    "            group_by(\"gameId\", \"playId\").\n",
    "            count().\n",
    "            filter(pl.col(\"count\") == 2).\n",
    "            drop(\"count\").\n",
    "            join(spec_data,\n",
    "                 on = [\"gameId\", \"playId\"],\n",
    "                 how = \"left\").\n",
    "            with_columns(pl.col(\"player_ID\").list.unique().list.lengths().alias(\"NB_unique\")).\n",
    "            filter(pl.col(\"NB_unique\") == 11).\n",
    "            drop(\"NB_unique\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = (new_data.\n",
    "              select(\"gameId\", \"playId\").\n",
    "              group_by(\"gameId\", \"playId\").\n",
    "              count().\n",
    "              filter(pl.col(\"count\") == 2).\n",
    "              drop(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = (base_index.\n",
    "            join(new_data,\n",
    "                 on = [\"gameId\", \"playId\"],\n",
    "                 how = \"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_sampling(df, sample_size):\n",
    "    to_insert = [[i for e in range(11)] for i in range(int(df.shape[0]/11)+1)]\n",
    "    to_insert = [e for s in to_insert for e in s][:df.shape[0]]\n",
    "    \n",
    "    full_random = (df.\n",
    "                   with_columns(pl.Series(to_insert).alias(\"ID\")).\n",
    "                   group_by(\"ID\").\n",
    "                   agg(\"position_ID\", \"player_ID\", \"OffDef_ID\", \"PlayType_ID\", \"team_ID\", \"down_ID\", \"season_ID\").\n",
    "                   sample(sample_size, with_replacement = True))\n",
    "    \n",
    "    return full_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter = (new_data.\n",
    "               explode(\"position_ID\", \"player_ID\").\n",
    "               drop(\"gameId\", \"playId\", \"yards_gained\", \"Success\").\n",
    "               select(pl.all().shuffle()))\n",
    "\n",
    "full_random = (reshape_for_sampling(starter, 84000).\n",
    "               with_columns(pl.lit(\"full_random\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_random_off = (starter.\n",
    "                   filter(pl.col(\"OffDef_ID\") == 1).\n",
    "                   unique(subset = \"player_ID\"))\n",
    "\n",
    "full_random_def = (starter.\n",
    "                   filter(pl.col(\"OffDef_ID\") == 0).\n",
    "                   unique(subset = \"player_ID\"))\n",
    "\n",
    "full_random_off = (reshape_for_sampling(full_random_off, 42000).\n",
    "                   with_columns(pl.lit(\"full_random_off_def\").alias(\"scheme\")))\n",
    "\n",
    "full_random_def = (reshape_for_sampling(full_random_def, 42000).\n",
    "                   with_columns(pl.lit(\"full_random_off_def\").alias(\"scheme\")))\n",
    "\n",
    "full_random_off_def = pl.concat([full_random_off, full_random_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_random_teams = [(starter.filter(pl.col(\"team_ID\") == v).unique(subset = \"player_ID\")) for v in np.unique(new_data.select(\"team_ID\").to_series().to_list())]\n",
    "\n",
    "full_random_teams = [reshape_for_sampling(d, 2400) for d in full_random_teams]\n",
    "\n",
    "full_random_team = (pl.concat(full_random_teams).\n",
    "                    with_columns(pl.lit(\"full_random_team\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = starter.select(\"team_ID\", \"season_ID\").to_pandas().drop_duplicates().to_dict(orient = \"records\")\n",
    "\n",
    "specific_teams = [(starter.\n",
    "                   filter(pl.col(\"team_ID\") == v[\"team_ID\"]).\n",
    "                   filter(pl.col(\"season_ID\") == v[\"season_ID\"]).\n",
    "                   unique(subset = \"player_ID\")) for v in filters]\n",
    "\n",
    "specific_teams = [reshape_for_sampling(d, 400) for d in specific_teams]\n",
    "\n",
    "specific_team = (pl.concat(specific_teams).\n",
    "                 with_columns(pl.lit(\"same_team_season\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = starter.select(\"season_ID\", \"OffDef_ID\").to_pandas().drop_duplicates().to_dict(orient = \"records\")\n",
    "\n",
    "specific_roles = [(starter.\n",
    "                   filter(pl.col(\"OffDef_ID\") == v[\"OffDef_ID\"]).\n",
    "                   filter(pl.col(\"season_ID\") == v[\"season_ID\"]).\n",
    "                   unique(subset = \"player_ID\")) for v in filters]\n",
    "\n",
    "specific_roles = [reshape_for_sampling(d, 10000) for d in specific_roles]\n",
    "\n",
    "specific_role = (pl.concat(specific_roles).\n",
    "                 with_columns(pl.lit(\"same_season_off_def\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = starter.select(\"OffDef_ID\", \"team_ID\").to_pandas().drop_duplicates().to_dict(orient = \"records\")\n",
    "\n",
    "specific_seasons = [(starter.\n",
    "                   filter(pl.col(\"OffDef_ID\") == v[\"OffDef_ID\"]).\n",
    "                   filter(pl.col(\"team_ID\") == v[\"team_ID\"]).\n",
    "                   unique(subset = \"player_ID\")) for v in filters]\n",
    "\n",
    "specific_seasons = [reshape_for_sampling(d, 1000) for d in specific_seasons]\n",
    "\n",
    "specific_season = (pl.concat(specific_roles).\n",
    "                   with_columns(pl.lit(\"same_team_off_def\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = starter.select(\"OffDef_ID\", \"team_ID\", \"season_ID\").to_pandas().drop_duplicates().to_dict(orient = \"records\")\n",
    "\n",
    "specific_playtypes = [(starter.\n",
    "                       filter(pl.col(\"OffDef_ID\") == v[\"OffDef_ID\"]).\n",
    "                       filter(pl.col(\"team_ID\") == v[\"team_ID\"]).\n",
    "                       filter(pl.col(\"season_ID\") == v[\"season_ID\"]).\n",
    "                       unique(subset = \"player_ID\")) for v in filters]\n",
    "\n",
    "specific_playtypes = [reshape_for_sampling(d, 300) for d in specific_playtypes]\n",
    "\n",
    "specific_playtype = (pl.concat(specific_playtypes).\n",
    "                     with_columns(pl.col(\"PlayType_ID\").list.unique().list.lengths().alias(\"NB_plays\")).\n",
    "                     filter(pl.col(\"NB_plays\") == 2).\n",
    "                     drop(\"NB_plays\").\n",
    "                     with_columns(pl.lit(\"same_team_season_offdef\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = starter.select(\"OffDef_ID\", \"team_ID\", \"season_ID\", \"PlayType_ID\").to_pandas().drop_duplicates().to_dict(orient = \"records\")\n",
    "\n",
    "specific_playtypes_2 = [(starter.\n",
    "                       filter(pl.col(\"OffDef_ID\") == v[\"OffDef_ID\"]).\n",
    "                       filter(pl.col(\"team_ID\") == v[\"team_ID\"]).\n",
    "                       filter(pl.col(\"season_ID\") == v[\"season_ID\"]).\n",
    "                       filter(pl.col(\"PlayType_ID\") == v[\"PlayType_ID\"]).\n",
    "                       unique(subset = \"player_ID\")) for v in filters]\n",
    "\n",
    "specific_playtypes_2 = [reshape_for_sampling(d, 300) for d in specific_playtypes_2]\n",
    "\n",
    "specific_playtype_2 = (pl.concat(specific_playtypes_2).\n",
    "                     with_columns(pl.lit(\"same_team_season_offdef_playtype\").alias(\"scheme\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = (pl.concat([specific_season, specific_role, specific_team, full_random_off_def, full_random, specific_playtype, specific_playtype_2]).\n",
    "             with_columns(pl.lit(0).alias(\"Label\")).\n",
    "             drop(\"ID\").\n",
    "             with_columns([pl.col(\"OffDef_ID\").list.first().alias(\"OffDef_ID\"),\n",
    "                           pl.col(\"PlayType_ID\").list.first().alias(\"PlayType_ID\"),\n",
    "                           pl.col(\"team_ID\").list.first().alias(\"team_ID\"),\n",
    "                           pl.col(\"down_ID\").list.first().alias(\"down_ID\"),\n",
    "                           pl.col(\"season_ID\").list.first().alias(\"season_ID\")]))\n",
    "\n",
    "positives = (new_data.\n",
    "             drop(\"gameId\", \"playId\", \"yards_gained\", \"Success\").\n",
    "             with_columns(pl.lit(\"positives\").alias(\"scheme\")).\n",
    "             with_columns(pl.lit(1).alias(\"Label\")))\n",
    "\n",
    "len_total = positives.shape[0]+negatives.shape[0]\n",
    "\n",
    "full_dataset = (pl.concat([positives, negatives]).\n",
    "                with_columns(pl.Series(range(len_total)).alias(\"ID\")).\n",
    "                with_columns(pl.col(\"position_ID\").list.lengths().alias(\"Len\")).\n",
    "                filter(pl.col(\"Len\") == 11).\n",
    "                drop(\"Len\").\n",
    "                with_columns(pl.col(\"player_ID\").list.unique().list.lengths().alias(\"NB_unique\")).\n",
    "                filter(pl.col(\"NB_unique\") == 11).\n",
    "                drop(\"NB_unique\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheme</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full_random</td>\n",
       "      <td>80686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>same_season_off_def</td>\n",
       "      <td>139574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>same_team_season_offdef_playtype</td>\n",
       "      <td>267349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>same_team_season</td>\n",
       "      <td>89251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>full_random_off_def</td>\n",
       "      <td>83873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>same_team_season_offdef</td>\n",
       "      <td>133435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>same_team_off_def</td>\n",
       "      <td>139574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positives</td>\n",
       "      <td>404782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             scheme   count\n",
       "0                       full_random   80686\n",
       "1               same_season_off_def  139574\n",
       "2  same_team_season_offdef_playtype  267349\n",
       "3                  same_team_season   89251\n",
       "4               full_random_off_def   83873\n",
       "5           same_team_season_offdef  133435\n",
       "6                 same_team_off_def  139574\n",
       "7                         positives  404782"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_dataset.\n",
    " select(\"scheme\").\n",
    " group_by(\"scheme\").\n",
    " count()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>position_ID</th><th>player_ID</th><th>OffDef_ID</th><th>PlayType_ID</th><th>team_ID</th><th>down_ID</th><th>season_ID</th><th>scheme</th><th>Label</th><th>ID</th><th>NB_unique</th><th>Length</th></tr><tr><td>list[i64]</td><td>list[i64]</td><td>i32</td><td>i64</td><td>i64</td><td>i32</td><td>i32</td><td>str</td><td>i32</td><td>i64</td><td>u32</td><td>u32</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 12)\n",
       "┌─────────────┬───────────┬───────────┬─────────────┬───┬───────┬─────┬───────────┬────────┐\n",
       "│ position_ID ┆ player_ID ┆ OffDef_ID ┆ PlayType_ID ┆ … ┆ Label ┆ ID  ┆ NB_unique ┆ Length │\n",
       "│ ---         ┆ ---       ┆ ---       ┆ ---         ┆   ┆ ---   ┆ --- ┆ ---       ┆ ---    │\n",
       "│ list[i64]   ┆ list[i64] ┆ i32       ┆ i64         ┆   ┆ i32   ┆ i64 ┆ u32       ┆ u32    │\n",
       "╞═════════════╪═══════════╪═══════════╪═════════════╪═══╪═══════╪═════╪═══════════╪════════╡\n",
       "└─────────────┴───────────┴───────────┴─────────────┴───┴───────┴─────┴───────────┴────────┘"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_dataset.\n",
    " with_columns(pl.col(\"player_ID\").list.unique().list.lengths().alias(\"NB_unique\")).\n",
    " with_columns(pl.col(\"player_ID\").list.lengths().alias(\"Length\")).\n",
    " filter(pl.col(\"NB_unique\") != 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_df = (full_dataset.\n",
    "                 select(\"ID\", \"scheme\").\n",
    "                 unique()).to_pandas()\n",
    "\n",
    "train, test = train_test_split(train_test_df, test_size= 0.3, stratify = train_test_df[\"scheme\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df_helenos = (new_data.\n",
    "                         select(\"gameId\", \"playId\", \"Success\").\n",
    "                         unique()).to_pandas()\n",
    "\n",
    "train_helenos, test_helenos = train_test_split(train_test_df_helenos, test_size= 0.3, stratify = train_test_df_helenos[\"Success\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (pl.from_pandas(train).\n",
    "              drop(\"Label\").\n",
    "              join(full_dataset,\n",
    "                   on = \"ID\",\n",
    "                   how = \"left\"))\n",
    "\n",
    "test_data = (pl.from_pandas(test).\n",
    "             drop(\"Label\").\n",
    "             join(full_dataset,\n",
    "                  on = \"ID\",\n",
    "                  how = \"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_helenos = (pl.from_pandas(train_helenos).\n",
    "                      drop(\"Success\").\n",
    "                      join(new_data,\n",
    "                           on = [\"gameId\", \"playId\"],\n",
    "                           how = \"left\"))\n",
    "\n",
    "test_data_helenos = (pl.from_pandas(test_helenos).\n",
    "                     drop(\"Success\").\n",
    "                     join(new_data,\n",
    "                          on = [\"gameId\", \"playId\"],\n",
    "                          how = \"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404782"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_helenos.shape[0] + test_data_helenos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_val = 0\n",
    "scrim_val = 99\n",
    "start_val = 1032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_dict = {row[\"ID\"] : \n",
    "    {\"input_ids\" : [10877 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"player_ids\": row[\"player_ID\"],\n",
    "     \"position_ids\": row[\"position_ID\"],\n",
    "     \"OffDef\" : [row[\"OffDef_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"token_type_ids\" : [0 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"pos_ids\" : [pos_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"team_ID\" : [row[\"team_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"start_ids\" : [start_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"scrim_ids\" : [scrim_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"attention_mask\" : [1 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"spec_token\" : [0],\n",
    "     \"PlayType\" : [row[\"PlayType_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"down_ID\" : [row[\"down_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"season_ID\" : [row[\"season_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"label\" : row[\"Label\"]} for row in train_data.iter_rows(named=True)}\n",
    "\n",
    "test_seq_dict = {row[\"ID\"] : \n",
    "    {\"input_ids\" : [10877 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"player_ids\": row[\"player_ID\"],\n",
    "     \"position_ids\": row[\"position_ID\"],\n",
    "     \"OffDef\" : [row[\"OffDef_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"token_type_ids\" : [0 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"pos_ids\" : [pos_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"team_ID\" : [row[\"team_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"start_ids\" : [start_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"scrim_ids\" : [scrim_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"attention_mask\" : [1 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"spec_token\" : [0],\n",
    "     \"PlayType\" : [row[\"PlayType_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"down_ID\" : [row[\"down_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"season_ID\" : [row[\"season_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"label\" : row[\"Label\"]} for row in test_data.iter_rows(named=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_helenos = {str(row[\"gameId\"]) + \"_\" + str(row[\"playId\"]) + \"_\" + str(row[\"OffDef_ID\"]) : \n",
    "    {\"input_ids\" : [10877 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"player_ids\": row[\"player_ID\"],\n",
    "     \"position_ids\": row[\"position_ID\"],\n",
    "     \"OffDef\" : [row[\"OffDef_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"token_type_ids\" : [0 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"pos_ids\" : [pos_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"team_ID\" : [row[\"team_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"start_ids\" : [start_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"scrim_ids\" : [scrim_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"attention_mask\" : [1 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"spec_token\" : [0],\n",
    "     \"PlayType\" : [row[\"PlayType_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"down_ID\" : [row[\"down_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"season_ID\" : [row[\"season_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"Success\" : row[\"Success\"], \n",
    "     \"yards_gained\" : row[\"yards_gained\"],\n",
    "     \"gameId\" : row[\"gameId\"],\n",
    "     \"playId\" : row[\"playId\"]} for row in train_data_helenos.iter_rows(named=True)}\n",
    "\n",
    "test_seq_helenos = {str(row[\"gameId\"]) + \"_\" + str(row[\"playId\"]) + \"_\" + str(row[\"OffDef_ID\"]) : \n",
    "    {\"input_ids\" : [10877 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"player_ids\": row[\"player_ID\"],\n",
    "     \"position_ids\": row[\"position_ID\"],\n",
    "     \"OffDef\" : [row[\"OffDef_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"token_type_ids\" : [0 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"pos_ids\" : [pos_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"team_ID\" : [row[\"team_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"start_ids\" : [start_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"scrim_ids\" : [scrim_val for i in range(len(row[\"position_ID\"]))],\n",
    "     \"attention_mask\" : [1 for i in range(len(row[\"position_ID\"]))],\n",
    "     \"spec_token\" : [0],\n",
    "     \"PlayType\" : [row[\"PlayType_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"down_ID\" : [row[\"down_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"season_ID\" : [row[\"season_ID\"] for i in range(len(row[\"position_ID\"]))],\n",
    "     \"Success\" : row[\"Success\"], \n",
    "     \"yards_gained\" : row[\"yards_gained\"],\n",
    "     \"gameId\" : row[\"gameId\"],\n",
    "     \"playId\" : row[\"playId\"]} for row in test_data_helenos.iter_rows(named=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_common_keys = np.unique([str(row[\"gameId\"]) + \"_\" + str(row[\"playId\"]) for row in train_data_helenos.iter_rows(named=True)])\n",
    "train_off_keys = [v + \"_1\" for v in train_common_keys]\n",
    "train_def_keys = [v + \"_0\" for v in train_common_keys]\n",
    "\n",
    "test_common_keys = np.unique([str(row[\"gameId\"]) + \"_\" + str(row[\"playId\"]) for row in test_data_helenos.iter_rows(named=True)])\n",
    "test_off_keys = [v + \"_1\" for v in test_common_keys]\n",
    "test_def_keys = [v + \"_0\" for v in test_common_keys]\n",
    "\n",
    "train_off_seq = [train_seq_helenos[v] for v in train_off_keys]\n",
    "train_def_seq = [train_seq_helenos[v] for v in train_def_keys]\n",
    "\n",
    "test_off_seq = [test_seq_helenos[v] for v in test_off_keys]\n",
    "test_def_seq = [test_seq_helenos[v] for v in test_def_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compile_seq(list_of_trajs):\n",
    "    merged_dict = {k : [] for k in list_of_trajs[0].keys()}\n",
    "\n",
    "    with tqdm(total=len(list_of_trajs)) as pbar:\n",
    "      for d in list_of_trajs:\n",
    "        for key, value in d.items():\n",
    "          merged_dict[key] += [value]\n",
    "        pbar.update(1)\n",
    "        \n",
    "    merged_dict = {k: np.array(v) for k,v in merged_dict.items()}\n",
    "    return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141673/141673 [00:00<00:00, 541741.66it/s]\n",
      "100%|██████████| 141673/141673 [00:00<00:00, 628451.38it/s]\n",
      "100%|██████████| 60718/60718 [00:00<00:00, 529530.50it/s]\n",
      "100%|██████████| 60718/60718 [00:00<00:00, 607983.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train_OFF_helenos = compile_seq(train_off_seq)\n",
    "train_DEF_helenos = compile_seq(train_def_seq)\n",
    "\n",
    "test_OFF_helenos = compile_seq(test_off_seq)\n",
    "test_DEF_helenos = compile_seq(test_def_seq)\n",
    "\n",
    "\n",
    "train_helenos = {\"off\" : train_OFF_helenos,\n",
    "                 \"def\" : train_DEF_helenos}\n",
    "\n",
    "test_helenos = {\"off\" : test_OFF_helenos,\n",
    "                \"def\" : test_DEF_helenos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 936966/936966 [00:01<00:00, 862349.59it/s]\n",
      "100%|██████████| 401558/401558 [00:00<00:00, 855290.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train = compile_seq(list(train_seq_dict.values()))\n",
    "test = compile_seq(list(test_seq_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_total = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_labels = tf.data.Dataset.from_tensor_slices(train[\"label\"])\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((train_total, train_labels))\n",
    "\n",
    "test_total = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_labels = tf.data.Dataset.from_tensor_slices(test[\"label\"])\n",
    "\n",
    "test_dataset = tf.data.Dataset.zip((test_total, test_labels))\n",
    "\n",
    "tf.data.Dataset.save(train_dataset, \"data_models/StratFormer/train_data\")\n",
    "tf.data.Dataset.save(test_dataset, \"data_models/StratFormer/test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_helenos)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_helenos)\n",
    "\n",
    "tf.data.Dataset.save(train_dataset, \"data_models/Helenos/train_data\")\n",
    "tf.data.Dataset.save(test_dataset, \"data_models/Helenos/test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['off', 'def'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helenos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = tf.data.Dataset.from_tensor_slices(train_helenos)\n",
    "train_labels = tf.data.Dataset.from_tensor_slices(train_helenos[\"off\"][\"yards_gained\"].astype(\"float32\"))\n",
    "train_dataset = tf.data.Dataset.zip((train_total, train_labels))\n",
    "\n",
    "test_total = tf.data.Dataset.from_tensor_slices(test_helenos)\n",
    "test_labels = tf.data.Dataset.from_tensor_slices(test_helenos[\"off\"][\"yards_gained\"].astype(\"float32\"))\n",
    "test_dataset = tf.data.Dataset.zip((test_total, test_labels))\n",
    "\n",
    "tf.data.Dataset.save(train_dataset, \"data_models/Helenos/train_data_tfp\")\n",
    "tf.data.Dataset.save(test_dataset, \"data_models/Helenos/test_data_tfp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nflgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
